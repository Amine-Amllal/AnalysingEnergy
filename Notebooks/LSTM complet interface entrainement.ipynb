{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5467ab3c",
   "metadata": {},
   "source": [
    "# ğŸ”‹ LSTM Complet Interface EntraÃ®nement - SystÃ¨me de PrÃ©diction Ã‰nergÃ©tique\n",
    "\n",
    "## ğŸ¯ Objectif\n",
    "Ce notebook permet Ã  l'utilisateur de choisir entre :\n",
    "1. **Utiliser les modÃ¨les prÃ©-entraÃ®nÃ©s** de la rÃ©gion Benten \n",
    "2. **RÃ©-entraÃ®ner de nouveaux modÃ¨les** sur ses propres donnÃ©es\n",
    "\n",
    "Le notebook combine les fonctionnalitÃ©s de \"LSTM complet\" et \"LSTM Generation\" sans optimisation Optuna pour rÃ©duire le temps d'exÃ©cution.\n",
    "\n",
    "## ğŸ“‹ Structure du Notebook\n",
    "1. **Configuration et choix utilisateur** - SÃ©lection du mode d'utilisation\n",
    "2. **Chargement et prÃ©paration des donnÃ©es** - Import et preprocessing\n",
    "3. **ModÃ¨les prÃ©-entraÃ®nÃ©s OU EntraÃ®nement** - Selon le choix utilisateur\n",
    "4. **PrÃ©dictions et Ã©valuation** - GÃ©nÃ©ration des rÃ©sultats\n",
    "5. **Sauvegarde et export** - Enregistrement des modÃ¨les et rÃ©sultats\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01366afe",
   "metadata": {},
   "source": [
    "## ğŸ“š 1. Importation des BibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothÃ¨ques essentielles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Preprocessing et mÃ©triques\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilitaires\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(\"âœ… Toutes les bibliothÃ¨ques ont Ã©tÃ© importÃ©es avec succÃ¨s!\")\n",
    "print(f\"ğŸ”§ Version TensorFlow: {tf.__version__}\")\n",
    "print(f\"ğŸ“Š Version Pandas: {pd.__version__}\")\n",
    "print(f\"ğŸ”¢ Version NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa94b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des variables d'environnement\n",
    "import os\n",
    "\n",
    "# Variables configurables depuis l'interface Streamlit\n",
    "LSTM_MODE = os.environ.get('LSTM_MODE', 'pretrained')  # 'pretrained' ou 'retrain'\n",
    "DATA_FILE = os.environ.get('DATA_FILE', 'data.csv')\n",
    "STREAMLIT_MODE = os.environ.get('STREAMLIT_MODE', 'false').lower() == 'true'\n",
    "\n",
    "print(f\"ğŸ”§ Configuration d'environnement :\")\n",
    "print(f\"   â€¢ Mode LSTM : {LSTM_MODE}\")\n",
    "print(f\"   â€¢ Fichier de donnÃ©es : {DATA_FILE}\")\n",
    "print(f\"   â€¢ ExÃ©cution Streamlit : {STREAMLIT_MODE}\")\n",
    "\n",
    "# Configuration pour compatibilitÃ© avec l'interface\n",
    "if STREAMLIT_MODE:\n",
    "    print(\"ğŸ–¥ï¸ Mode interface Streamlit activÃ© - Configuration automatique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02c6a5",
   "metadata": {},
   "source": [
    "## âš™ï¸ 2. Configuration et Choix Utilisateur\n",
    "\n",
    "Choisissez le mode d'utilisation :\n",
    "- **Mode 1** : Utiliser les modÃ¨les prÃ©-entraÃ®nÃ©s de la rÃ©gion Benten\n",
    "- **Mode 2** : RÃ©-entraÃ®ner de nouveaux modÃ¨les sur vos donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des chemins\n",
    "DATA_PATH = \"../Data/\"\n",
    "MODELS_PATH = \"models/\"\n",
    "SCALERS_PATH = \"scalers/\"\n",
    "\n",
    "# CrÃ©er les dossiers s'ils n'existent pas\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(SCALERS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ”‹ SystÃ¨me de PrÃ©diction Ã‰nergÃ©tique LSTM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables globales pour stocker les choix\n",
    "selected_mode = None\n",
    "selected_data_file = None\n",
    "\n",
    "if STREAMLIT_MODE:\n",
    "    # En mode Streamlit, utiliser les variables d'environnement\n",
    "    selected_mode = LSTM_MODE\n",
    "    selected_data_file = DATA_FILE\n",
    "    print(\"ğŸ”§ Configuration automatique (mode Streamlit):\")\n",
    "    print(f\"ğŸ“Š Mode sÃ©lectionnÃ©: {selected_mode}\")\n",
    "    print(f\"ğŸ“ Fichier de donnÃ©es: {selected_data_file}\")\n",
    "    \n",
    "    if selected_mode == 'pretrained':\n",
    "        print(\"ğŸ¯ Vous allez utiliser les modÃ¨les prÃ©-entraÃ®nÃ©s de la rÃ©gion Benten\")\n",
    "    else:\n",
    "        print(\"ğŸ”„ Vous allez rÃ©-entraÃ®ner de nouveaux modÃ¨les\")\n",
    "        \n",
    "else:\n",
    "    # Mode interactif avec widgets\n",
    "    # Interface de choix utilisateur\n",
    "    mode_selection = widgets.RadioButtons(\n",
    "        options=[\n",
    "            ('ğŸ¯ Utiliser les modÃ¨les prÃ©-entraÃ®nÃ©s (RÃ©gion Benten)', 'pretrained'),\n",
    "            ('ğŸ”„ RÃ©-entraÃ®ner de nouveaux modÃ¨les', 'retrain')\n",
    "        ],\n",
    "        value='pretrained',\n",
    "        description='Mode:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Widget de sÃ©lection du fichier de donnÃ©es\n",
    "    data_file_selection = widgets.Dropdown(\n",
    "        options=['data.csv', 'train_data.csv', 'test_data.csv', 'uploaded_test_data.csv'],\n",
    "        value='data.csv',\n",
    "        description='Fichier de donnÃ©es:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Bouton pour confirmer la sÃ©lection\n",
    "    confirm_button = widgets.Button(\n",
    "        description=\"âœ… Confirmer la sÃ©lection\",\n",
    "        button_style='success',\n",
    "        tooltip='Cliquez pour confirmer votre choix'\n",
    "    )\n",
    "\n",
    "    def on_confirm_clicked(b):\n",
    "        global selected_mode, selected_data_file\n",
    "        selected_mode = mode_selection.value\n",
    "        selected_data_file = data_file_selection.value\n",
    "        \n",
    "        clear_output()\n",
    "        print(\"âœ… Configuration confirmÃ©e!\")\n",
    "        print(f\"ğŸ“Š Mode sÃ©lectionnÃ©: {selected_mode}\")\n",
    "        print(f\"ğŸ“ Fichier de donnÃ©es: {selected_data_file}\")\n",
    "        \n",
    "        if selected_mode == 'pretrained':\n",
    "            print(\"ğŸ¯ Vous allez utiliser les modÃ¨les prÃ©-entraÃ®nÃ©s de la rÃ©gion Benten\")\n",
    "        else:\n",
    "            print(\"ğŸ”„ Vous allez rÃ©-entraÃ®ner de nouveaux modÃ¨les\")\n",
    "\n",
    "    confirm_button.on_click(on_confirm_clicked)\n",
    "\n",
    "    # Affichage de l'interface\n",
    "    print(\"ğŸ”§ Configuration manuelle (mode interactif):\")\n",
    "    display(mode_selection)\n",
    "    display(data_file_selection)\n",
    "    display(confirm_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc71b3",
   "metadata": {},
   "source": [
    "## ğŸ“Š 3. Chargement et PrÃ©paration des DonnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de chargement des donnÃ©es\n",
    "def load_and_prepare_data(file_name):\n",
    "    \"\"\"Charge et prÃ©pare les donnÃ©es pour l'entraÃ®nement LSTM\"\"\"\n",
    "    try:\n",
    "        # Chargement des donnÃ©es\n",
    "        data_path = os.path.join(DATA_PATH, file_name)\n",
    "        data = pd.read_csv(data_path)\n",
    "        \n",
    "        print(f\"âœ… DonnÃ©es chargÃ©es depuis: {data_path}\")\n",
    "        print(f\"ğŸ“Š Forme des donnÃ©es: {data.shape}\")\n",
    "        print(f\"ğŸ“‹ Colonnes disponibles: {list(data.columns)}\")\n",
    "        \n",
    "        # VÃ©rification de la colonne date\n",
    "        if 'date' in data.columns:\n",
    "            data['date'] = pd.to_datetime(data['date'])\n",
    "            data = data.sort_values('date')\n",
    "            print(\"ğŸ“… Colonne date formatÃ©e et donnÃ©es triÃ©es\")\n",
    "        \n",
    "        # Identification des colonnes de prÃ©diction\n",
    "        prediction_columns = [col for col in data.columns if col != 'date']\n",
    "        print(f\"ğŸ¯ Colonnes de prÃ©diction: {prediction_columns}\")\n",
    "        \n",
    "        # VÃ©rification des valeurs manquantes\n",
    "        missing_values = data.isnull().sum()\n",
    "        if missing_values.sum() > 0:\n",
    "            print(\"âš ï¸ Valeurs manquantes dÃ©tectÃ©es:\")\n",
    "            print(missing_values[missing_values > 0])\n",
    "            data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "            print(\"âœ… Valeurs manquantes corrigÃ©es\")\n",
    "        \n",
    "        return data, prediction_columns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors du chargement des donnÃ©es: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# DÃ©terminer le fichier de donnÃ©es Ã  utiliser\n",
    "if STREAMLIT_MODE:\n",
    "    # En mode Streamlit, utiliser le fichier tÃ©lÃ©versÃ©\n",
    "    data_file_to_use = selected_data_file if 'selected_data_file' in globals() else DATA_FILE\n",
    "    print(f\"ğŸ”§ Mode Streamlit: Utilisation du fichier {data_file_to_use}\")\n",
    "else:\n",
    "    # En mode interactif, utiliser la sÃ©lection utilisateur ou fichier par dÃ©faut\n",
    "    data_file_to_use = selected_data_file if 'selected_data_file' in globals() and selected_data_file else 'data.csv'\n",
    "    print(f\"ğŸ”§ Mode interactif: Utilisation du fichier {data_file_to_use}\")\n",
    "\n",
    "# Chargement des donnÃ©es\n",
    "data, prediction_columns = load_and_prepare_data(data_file_to_use)\n",
    "\n",
    "if data is not None:\n",
    "    print(\"\\nğŸ“ˆ AperÃ§u des donnÃ©es:\")\n",
    "    display(data.head())\n",
    "    \n",
    "    print(\"\\nğŸ“Š Statistiques descriptives:\")\n",
    "    display(data.describe())\n",
    "    \n",
    "    # Visualisation des donnÃ©es (seulement en mode non-Streamlit pour Ã©viter les conflits)\n",
    "    if not STREAMLIT_MODE:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Graphique temporel si colonne date disponible\n",
    "        if 'date' in data.columns:\n",
    "            for i, col in enumerate(prediction_columns[:4]):  # Limite Ã  4 colonnes pour la lisibilitÃ©\n",
    "                plt.subplot(2, 2, i+1)\n",
    "                plt.plot(data['date'], data[col])\n",
    "                plt.title(f'Ã‰volution de {col}')\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel(col)\n",
    "                plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"ğŸ“Š Visualisations dÃ©sactivÃ©es en mode Streamlit\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Impossible de charger les donnÃ©es. VÃ©rifiez le nom du fichier.\")\n",
    "    if STREAMLIT_MODE:\n",
    "        raise FileNotFoundError(f\"Fichier de donnÃ©es non trouvÃ©: {data_file_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cd74a",
   "metadata": {},
   "source": [
    "## ğŸ¯ 4. Choix entre ModÃ¨les PrÃ©-entraÃ®nÃ©s et RÃ©-entraÃ®nement\n",
    "\n",
    "Cette section exÃ©cute diffÃ©rents processus selon votre choix :\n",
    "- **ModÃ¨les prÃ©-entraÃ®nÃ©s** : Chargement des modÃ¨les de la rÃ©gion Benten\n",
    "- **RÃ©-entraÃ®nement** : CrÃ©ation et entraÃ®nement de nouveaux modÃ¨les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03103f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions utilitaires pour le preprocessing\n",
    "def create_sequences(data, target_col, sequence_length=60):\n",
    "    \"\"\"CrÃ©e des sÃ©quences pour l'entraÃ®nement LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i])\n",
    "        y.append(data[i, target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_data_for_training(data, target_columns, sequence_length=60, test_size=0.2):\n",
    "    \"\"\"PrÃ©pare les donnÃ©es pour l'entraÃ®nement\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for target_col in target_columns:\n",
    "        print(f\"\\nğŸ¯ PrÃ©paration des donnÃ©es pour: {target_col}\")\n",
    "        \n",
    "        # SÃ©lection des features (toutes les colonnes numÃ©riques)\n",
    "        feature_columns = [col for col in data.columns if col != 'date' and data[col].dtype in ['float64', 'int64']]\n",
    "        features_data = data[feature_columns].values\n",
    "        \n",
    "        # Normalisation\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(features_data)\n",
    "        \n",
    "        # Index de la colonne cible\n",
    "        target_idx = feature_columns.index(target_col)\n",
    "        \n",
    "        # CrÃ©ation des sÃ©quences\n",
    "        X, y = create_sequences(scaled_data, target_idx, sequence_length)\n",
    "        \n",
    "        # Division train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, shuffle=False\n",
    "        )\n",
    "        \n",
    "        results[target_col] = {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'scaler': scaler,\n",
    "            'feature_columns': feature_columns\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… DonnÃ©es prÃ©parÃ©es - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Fonction pour crÃ©er un modÃ¨le LSTM\n",
    "def create_lstm_model(input_shape, neurons=[50, 50], dropout_rate=0.2):\n",
    "    \"\"\"CrÃ©e un modÃ¨le LSTM avec architecture simple\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # PremiÃ¨re couche LSTM\n",
    "    model.add(LSTM(neurons[0], return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # DeuxiÃ¨me couche LSTM\n",
    "    model.add(LSTM(neurons[1], return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Couche de sortie\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compilation\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# VÃ©rification des variables d'environnement pour compatibilitÃ© Streamlit\n",
    "if STREAMLIT_MODE:\n",
    "    # En mode Streamlit, utiliser les variables d'environnement\n",
    "    selected_mode = LSTM_MODE\n",
    "    selected_data_file = DATA_FILE\n",
    "    print(f\"ğŸ”§ Mode Streamlit dÃ©tectÃ© - Configuration automatique:\")\n",
    "    print(f\"   â€¢ Mode: {selected_mode}\")\n",
    "    print(f\"   â€¢ Fichier: {selected_data_file}\")\n",
    "\n",
    "# ExÃ©cution selon le mode choisi\n",
    "if 'selected_mode' in globals() and selected_mode and data is not None:\n",
    "    \n",
    "    if selected_mode == 'pretrained':\n",
    "        print(\"ğŸ¯ Mode: Utilisation des modÃ¨les prÃ©-entraÃ®nÃ©s\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # VÃ©rification de l'existence des modÃ¨les prÃ©-entraÃ®nÃ©s\n",
    "        pretrained_models = {}\n",
    "        available_models = []\n",
    "        \n",
    "        for col in prediction_columns:\n",
    "            model_path = os.path.join(MODELS_PATH, f\"{col}_LSTM.h5\")\n",
    "            scaler_path = os.path.join(SCALERS_PATH, f\"{col}_scaler.pkl\")\n",
    "            \n",
    "            if os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "                try:\n",
    "                    model = load_model(model_path)\n",
    "                    with open(scaler_path, 'rb') as f:\n",
    "                        scaler = pickle.load(f)\n",
    "                    \n",
    "                    pretrained_models[col] = {'model': model, 'scaler': scaler}\n",
    "                    available_models.append(col)\n",
    "                    print(f\"âœ… ModÃ¨le prÃ©-entraÃ®nÃ© chargÃ© pour: {col}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Erreur lors du chargement du modÃ¨le {col}: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ ModÃ¨le prÃ©-entraÃ®nÃ© non trouvÃ© pour: {col}\")\n",
    "        \n",
    "        if available_models:\n",
    "            print(f\"\\nğŸ‰ {len(available_models)} modÃ¨les prÃ©-entraÃ®nÃ©s disponibles!\")\n",
    "            models_ready = True\n",
    "        else:\n",
    "            print(\"âŒ Aucun modÃ¨le prÃ©-entraÃ®nÃ© trouvÃ©. Passez au mode rÃ©-entraÃ®nement.\")\n",
    "            models_ready = False\n",
    "    \n",
    "    else:  # Mode rÃ©-entraÃ®nement\n",
    "        print(\"ğŸ”„ Mode: RÃ©-entraÃ®nement de nouveaux modÃ¨les\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # PrÃ©paration des donnÃ©es pour l'entraÃ®nement\n",
    "        training_data = prepare_data_for_training(data, prediction_columns)\n",
    "        trained_models = {}\n",
    "        \n",
    "        for target_col in prediction_columns:\n",
    "            print(f\"\\nğŸš€ EntraÃ®nement du modÃ¨le pour: {target_col}\")\n",
    "            \n",
    "            # RÃ©cupÃ©ration des donnÃ©es prÃ©parÃ©es\n",
    "            data_dict = training_data[target_col]\n",
    "            X_train, y_train = data_dict['X_train'], data_dict['y_train']\n",
    "            X_test, y_test = data_dict['X_test'], data_dict['y_test']\n",
    "            \n",
    "            # CrÃ©ation du modÃ¨le\n",
    "            input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "            model = create_lstm_model(input_shape)\n",
    "            \n",
    "            print(f\"ğŸ“Š Architecture du modÃ¨le: {model.summary()}\")\n",
    "            \n",
    "            # Callbacks\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            \n",
    "            # EntraÃ®nement\n",
    "            print(\"ğŸ”„ DÃ©but de l'entraÃ®nement...\")\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=50,  # Nombre d'Ã©poques rÃ©duit pour Ã©conomiser du temps\n",
    "                batch_size=32,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Sauvegarde du modÃ¨le et du scaler\n",
    "            model_path = os.path.join(MODELS_PATH, f\"{target_col}_LSTM.h5\")\n",
    "            scaler_path = os.path.join(SCALERS_PATH, f\"{target_col}_scaler.pkl\")\n",
    "            \n",
    "            model.save(model_path)\n",
    "            with open(scaler_path, 'wb') as f:\n",
    "                pickle.dump(data_dict['scaler'], f)\n",
    "            \n",
    "            trained_models[target_col] = {\n",
    "                'model': model,\n",
    "                'scaler': data_dict['scaler'],\n",
    "                'history': history,\n",
    "                'test_data': (X_test, y_test)\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… ModÃ¨le entraÃ®nÃ© et sauvegardÃ© pour: {target_col}\")\n",
    "            \n",
    "            # Affichage de la courbe d'apprentissage\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.history['loss'], label='Train Loss')\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "            plt.title(f'Courbe d\\'apprentissage - {target_col}')\n",
    "            plt.xlabel('Ã‰poque')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history['mae'], label='Train MAE')\n",
    "            plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "            plt.title(f'Erreur absolue moyenne - {target_col}')\n",
    "            plt.xlabel('Ã‰poque')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"\\nğŸ‰ EntraÃ®nement terminÃ© pour {len(trained_models)} modÃ¨les!\")\n",
    "        models_ready = True\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Veuillez d'abord confirmer votre sÃ©lection et charger les donnÃ©es.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77def5",
   "metadata": {},
   "source": [
    "## ğŸ”® 5. GÃ©nÃ©ration des PrÃ©dictions\n",
    "\n",
    "Cette section utilise les modÃ¨les (prÃ©-entraÃ®nÃ©s ou nouvellement entraÃ®nÃ©s) pour gÃ©nÃ©rer des prÃ©dictions sur les donnÃ©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac622a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour gÃ©nÃ©rer des prÃ©dictions\n",
    "def generate_predictions(models_dict, data, sequence_length=60, prediction_days=30):\n",
    "    \"\"\"GÃ©nÃ¨re des prÃ©dictions avec les modÃ¨les disponibles\"\"\"\n",
    "    predictions_results = {}\n",
    "    \n",
    "    for target_col, model_info in models_dict.items():\n",
    "        print(f\"\\nğŸ”® GÃ©nÃ©ration des prÃ©dictions pour: {target_col}\")\n",
    "        \n",
    "        model = model_info['model']\n",
    "        scaler = model_info['scaler']\n",
    "        \n",
    "        # PrÃ©paration des donnÃ©es pour prÃ©diction\n",
    "        feature_columns = [col for col in data.columns if col != 'date' and data[col].dtype in ['float64', 'int64']]\n",
    "        features_data = data[feature_columns].values\n",
    "        \n",
    "        # Normalisation avec le scaler du modÃ¨le\n",
    "        scaled_data = scaler.transform(features_data)\n",
    "        \n",
    "        # Index de la colonne cible\n",
    "        target_idx = feature_columns.index(target_col)\n",
    "        \n",
    "        # Prendre les derniÃ¨res sÃ©quences pour commencer les prÃ©dictions\n",
    "        last_sequence = scaled_data[-sequence_length:]\n",
    "        \n",
    "        # GÃ©nÃ©ration des prÃ©dictions futures\n",
    "        future_predictions = []\n",
    "        current_sequence = last_sequence.copy()\n",
    "        \n",
    "        for _ in range(prediction_days):\n",
    "            # Reshape pour le modÃ¨le LSTM\n",
    "            input_seq = current_sequence.reshape(1, sequence_length, len(feature_columns))\n",
    "            \n",
    "            # PrÃ©diction\n",
    "            pred = model.predict(input_seq, verbose=0)[0, 0]\n",
    "            future_predictions.append(pred)\n",
    "            \n",
    "            # Mettre Ã  jour la sÃ©quence pour la prochaine prÃ©diction\n",
    "            new_row = current_sequence[-1].copy()\n",
    "            new_row[target_idx] = pred\n",
    "            \n",
    "            # DÃ©caler la sÃ©quence\n",
    "            current_sequence = np.vstack([current_sequence[1:], new_row])\n",
    "        \n",
    "        # DÃ©normalisation des prÃ©dictions\n",
    "        # CrÃ©er un array temporaire pour la dÃ©normalisation\n",
    "        temp_array = np.zeros((len(future_predictions), len(feature_columns)))\n",
    "        temp_array[:, target_idx] = future_predictions\n",
    "        denormalized = scaler.inverse_transform(temp_array)\n",
    "        final_predictions = denormalized[:, target_idx]\n",
    "        \n",
    "        # PrÃ©dictions sur les donnÃ©es historiques pour Ã©valuation\n",
    "        historical_predictions = []\n",
    "        for i in range(sequence_length, len(scaled_data)):\n",
    "            input_seq = scaled_data[i-sequence_length:i].reshape(1, sequence_length, len(feature_columns))\n",
    "            pred = model.predict(input_seq, verbose=0)[0, 0]\n",
    "            historical_predictions.append(pred)\n",
    "        \n",
    "        # DÃ©normalisation des prÃ©dictions historiques\n",
    "        temp_hist = np.zeros((len(historical_predictions), len(feature_columns)))\n",
    "        temp_hist[:, target_idx] = historical_predictions\n",
    "        denorm_hist = scaler.inverse_transform(temp_hist)\n",
    "        final_hist_predictions = denorm_hist[:, target_idx]\n",
    "        \n",
    "        # Stockage des rÃ©sultats\n",
    "        predictions_results[target_col] = {\n",
    "            'future_predictions': final_predictions,\n",
    "            'historical_predictions': final_hist_predictions,\n",
    "            'actual_values': data[target_col].values[sequence_length:],\n",
    "            'feature_columns': feature_columns,\n",
    "            'dates': data['date'].values if 'date' in data.columns else None\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… {len(final_predictions)} prÃ©dictions futures gÃ©nÃ©rÃ©es\")\n",
    "        print(f\"ğŸ“Š {len(final_hist_predictions)} prÃ©dictions historiques gÃ©nÃ©rÃ©es\")\n",
    "    \n",
    "    return predictions_results\n",
    "\n",
    "# GÃ©nÃ©ration des prÃ©dictions selon le mode\n",
    "if 'models_ready' in globals() and models_ready:\n",
    "    print(\"ğŸ”® GÃ©nÃ©ration des prÃ©dictions en cours...\")\n",
    "    \n",
    "    # SÃ©lection des modÃ¨les selon le mode\n",
    "    if selected_mode == 'pretrained':\n",
    "        active_models = pretrained_models\n",
    "        print(\"ğŸ“Š Utilisation des modÃ¨les prÃ©-entraÃ®nÃ©s\")\n",
    "    else:\n",
    "        active_models = trained_models\n",
    "        print(\"ğŸ“Š Utilisation des modÃ¨les nouvellement entraÃ®nÃ©s\")\n",
    "    \n",
    "    # ParamÃ¨tres de prÃ©diction\n",
    "    SEQUENCE_LENGTH = 60\n",
    "    PREDICTION_DAYS = 30\n",
    "    \n",
    "    print(f\"âš™ï¸ ParamÃ¨tres: SÃ©quence={SEQUENCE_LENGTH}, PrÃ©dictions futures={PREDICTION_DAYS} jours\")\n",
    "    \n",
    "    # GÃ©nÃ©ration des prÃ©dictions\n",
    "    all_predictions = generate_predictions(\n",
    "        active_models, \n",
    "        data, \n",
    "        sequence_length=SEQUENCE_LENGTH, \n",
    "        prediction_days=PREDICTION_DAYS\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ‰ PrÃ©dictions gÃ©nÃ©rÃ©es pour {len(all_predictions)} variables!\")\n",
    "    \n",
    "    # Affichage des rÃ©sultats pour chaque variable\n",
    "    for target_col, results in all_predictions.items():\n",
    "        print(f\"\\nğŸ“ˆ RÃ©sultats pour {target_col}:\")\n",
    "        print(f\"   â€¢ PrÃ©dictions futures: {len(results['future_predictions'])} valeurs\")\n",
    "        print(f\"   â€¢ PrÃ©dictions historiques: {len(results['historical_predictions'])} valeurs\")\n",
    "        print(f\"   â€¢ Valeurs min/max futures: {results['future_predictions'].min():.2f} / {results['future_predictions'].max():.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Les modÃ¨les ne sont pas prÃªts. ExÃ©cutez d'abord les cellules prÃ©cÃ©dentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da05856",
   "metadata": {},
   "source": [
    "## ğŸ“Š 6. Ã‰valuation des ModÃ¨les\n",
    "\n",
    "Cette section Ã©value les performances des modÃ¨les en calculant diffÃ©rentes mÃ©triques et en gÃ©nÃ©rant des visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'Ã©valuation des modÃ¨les\n",
    "def evaluate_model_performance(predictions_results):\n",
    "    \"\"\"Ã‰value les performances des modÃ¨les avec diffÃ©rentes mÃ©triques\"\"\"\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    print(\"ğŸ“Š Ã‰valuation des performances des modÃ¨les\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for target_col, results in predictions_results.items():\n",
    "        print(f\"\\nğŸ¯ Ã‰valuation pour: {target_col}\")\n",
    "        \n",
    "        actual = results['actual_values']\n",
    "        predicted = results['historical_predictions']\n",
    "        \n",
    "        # Calcul des mÃ©triques\n",
    "        mse = mean_squared_error(actual, predicted)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(actual, predicted)\n",
    "        r2 = r2_score(actual, predicted)\n",
    "        \n",
    "        # MAPE (Mean Absolute Percentage Error)\n",
    "        mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "        \n",
    "        # Stockage des mÃ©triques\n",
    "        metrics = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'RÂ²': r2,\n",
    "            'MAPE': mape\n",
    "        }\n",
    "        \n",
    "        evaluation_results[target_col] = metrics\n",
    "        \n",
    "        # Affichage des mÃ©triques\n",
    "        print(f\"   ğŸ“ˆ MSE (Mean Squared Error): {mse:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ RÂ² (Coefficient de dÃ©termination): {r2:.4f}\")\n",
    "        print(f\"   ğŸ“ˆ MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "        \n",
    "        # InterprÃ©tation du RÂ²\n",
    "        if r2 >= 0.9:\n",
    "            print(\"   âœ… Excellent modÃ¨le (RÂ² â‰¥ 0.9)\")\n",
    "        elif r2 >= 0.8:\n",
    "            print(\"   ğŸŸ¢ Bon modÃ¨le (RÂ² â‰¥ 0.8)\")\n",
    "        elif r2 >= 0.6:\n",
    "            print(\"   ğŸŸ¡ ModÃ¨le acceptable (RÂ² â‰¥ 0.6)\")\n",
    "        else:\n",
    "            print(\"   ğŸ”´ ModÃ¨le Ã  amÃ©liorer (RÂ² < 0.6)\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "# Fonction de visualisation des rÃ©sultats\n",
    "def visualize_predictions(predictions_results, max_points=1000):\n",
    "    \"\"\"Visualise les prÃ©dictions vs valeurs rÃ©elles\"\"\"\n",
    "    n_models = len(predictions_results)\n",
    "    \n",
    "    # Calcul du nombre de lignes et colonnes pour les sous-graphiques\n",
    "    cols = min(2, n_models)\n",
    "    rows = (n_models + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * rows))\n",
    "    \n",
    "    for idx, (target_col, results) in enumerate(predictions_results.items()):\n",
    "        # Graphique 1: Comparaison prÃ©dictions vs rÃ©alitÃ©\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        \n",
    "        actual = results['actual_values']\n",
    "        predicted = results['historical_predictions']\n",
    "        \n",
    "        # Limitation du nombre de points pour la lisibilitÃ©\n",
    "        if len(actual) > max_points:\n",
    "            step = len(actual) // max_points\n",
    "            actual_plot = actual[::step]\n",
    "            predicted_plot = predicted[::step]\n",
    "        else:\n",
    "            actual_plot = actual\n",
    "            predicted_plot = predicted\n",
    "        \n",
    "        plt.plot(actual_plot, label='Valeurs rÃ©elles', alpha=0.7, linewidth=1)\n",
    "        plt.plot(predicted_plot, label='PrÃ©dictions', alpha=0.7, linewidth=1)\n",
    "        plt.title(f'PrÃ©dictions vs RÃ©alitÃ© - {target_col}')\n",
    "        plt.xlabel('Ã‰chantillons')\n",
    "        plt.ylabel('Valeurs')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Graphique des prÃ©dictions futures\n",
    "    plt.figure(figsize=(15, 5 * rows))\n",
    "    \n",
    "    for idx, (target_col, results) in enumerate(predictions_results.items()):\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        \n",
    "        future_pred = results['future_predictions']\n",
    "        \n",
    "        # Affichage des derniÃ¨res valeurs historiques pour contexte\n",
    "        if len(results['actual_values']) > 0:\n",
    "            last_actual = results['actual_values'][-30:]  # Derniers 30 points\n",
    "            x_hist = range(-len(last_actual), 0)\n",
    "            plt.plot(x_hist, last_actual, label='Historique rÃ©cent', color='blue', alpha=0.7)\n",
    "        \n",
    "        # PrÃ©dictions futures\n",
    "        x_future = range(0, len(future_pred))\n",
    "        plt.plot(x_future, future_pred, label='PrÃ©dictions futures', color='red', marker='o', markersize=3)\n",
    "        \n",
    "        plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5, label='DÃ©but des prÃ©dictions')\n",
    "        plt.title(f'PrÃ©dictions futures - {target_col}')\n",
    "        plt.xlabel('Jours')\n",
    "        plt.ylabel('Valeurs')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ExÃ©cution de l'Ã©valuation\n",
    "if 'all_predictions' in globals() and all_predictions:\n",
    "    print(\"ğŸ“Š DÃ©but de l'Ã©valuation des modÃ¨les...\")\n",
    "    \n",
    "    # Ã‰valuation des performances\n",
    "    model_metrics = evaluate_model_performance(all_predictions)\n",
    "    \n",
    "    # CrÃ©ation d'un DataFrame rÃ©capitulatif\n",
    "    metrics_df = pd.DataFrame(model_metrics).T\n",
    "    print(\"\\nğŸ“‹ RÃ©capitulatif des mÃ©triques:\")\n",
    "    display(metrics_df.round(4))\n",
    "    \n",
    "    # Visualisation des rÃ©sultats\n",
    "    print(\"\\nğŸ“ˆ GÃ©nÃ©ration des graphiques...\")\n",
    "    visualize_predictions(all_predictions)\n",
    "    \n",
    "    # Graphique en barres des mÃ©triques RÂ²\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    r2_values = [metrics['RÂ²'] for metrics in model_metrics.values()]\n",
    "    model_names = list(model_metrics.keys())\n",
    "    \n",
    "    colors = ['green' if r2 >= 0.8 else 'orange' if r2 >= 0.6 else 'red' for r2 in r2_values]\n",
    "    \n",
    "    plt.bar(model_names, r2_values, color=colors, alpha=0.7)\n",
    "    plt.title('Coefficient de dÃ©termination (RÂ²) par modÃ¨le')\n",
    "    plt.ylabel('RÂ²')\n",
    "    plt.xlabel('Variables')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ligne de rÃ©fÃ©rence pour un bon modÃ¨le\n",
    "    plt.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='Seuil bon modÃ¨le (0.8)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ… Ã‰valuation terminÃ©e!\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Aucune prÃ©diction trouvÃ©e. ExÃ©cutez d'abord la section de gÃ©nÃ©ration des prÃ©dictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db56b5d7",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 7. Sauvegarde et Export des RÃ©sultats\n",
    "\n",
    "Cette section sauvegarde les modÃ¨les, les mÃ©triques et exporte les rÃ©sultats dans diffÃ©rents formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02712177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de sauvegarde des rÃ©sultats\n",
    "def save_results(predictions_results, model_metrics, output_dir=\"results\"):\n",
    "    \"\"\"Sauvegarde les rÃ©sultats dans diffÃ©rents formats\"\"\"\n",
    "    \n",
    "    # CrÃ©er le dossier de rÃ©sultats\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ Sauvegarde des rÃ©sultats dans: {output_dir}/\")\n",
    "    \n",
    "    # 1. Sauvegarde des prÃ©dictions en CSV\n",
    "    for target_col, results in predictions_results.items():\n",
    "        # PrÃ©dictions futures\n",
    "        future_df = pd.DataFrame({\n",
    "            'jour': range(1, len(results['future_predictions']) + 1),\n",
    "            'prediction': results['future_predictions']\n",
    "        })\n",
    "        future_file = os.path.join(output_dir, f\"{target_col}_predictions_futures_{timestamp}.csv\")\n",
    "        future_df.to_csv(future_file, index=False)\n",
    "        print(f\"   âœ… PrÃ©dictions futures sauvÃ©es: {future_file}\")\n",
    "        \n",
    "        # PrÃ©dictions historiques vs rÃ©alitÃ©\n",
    "        historical_df = pd.DataFrame({\n",
    "            'valeur_reelle': results['actual_values'],\n",
    "            'prediction': results['historical_predictions'],\n",
    "            'erreur': results['actual_values'] - results['historical_predictions']\n",
    "        })\n",
    "        historical_file = os.path.join(output_dir, f\"{target_col}_evaluation_{timestamp}.csv\")\n",
    "        historical_df.to_csv(historical_file, index=False)\n",
    "        print(f\"   âœ… Ã‰valuation historique sauvÃ©e: {historical_file}\")\n",
    "    \n",
    "    # 2. Sauvegarde des mÃ©triques\n",
    "    metrics_df = pd.DataFrame(model_metrics).T\n",
    "    metrics_file = os.path.join(output_dir, f\"metriques_modeles_{timestamp}.csv\")\n",
    "    metrics_df.to_csv(metrics_file)\n",
    "    print(f\"   âœ… MÃ©triques sauvÃ©es: {metrics_file}\")\n",
    "    \n",
    "    # 3. Rapport de synthÃ¨se\n",
    "    report_file = os.path.join(output_dir, f\"rapport_synthese_{timestamp}.txt\")\n",
    "    with open(report_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"ğŸ”‹ RAPPORT DE SYNTHÃˆSE - SYSTÃˆME DE PRÃ‰DICTION Ã‰NERGÃ‰TIQUE\\\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\\\n\\\\n\")\n",
    "        f.write(f\"ğŸ“… Date de gÃ©nÃ©ration: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\\n\")\n",
    "        f.write(f\"ğŸ“Š Mode utilisÃ©: {selected_mode}\\\\n\")\n",
    "        f.write(f\"ğŸ“ Fichier de donnÃ©es: {selected_data_file}\\\\n\")\n",
    "        f.write(f\"ğŸ¯ Nombre de variables prÃ©dites: {len(predictions_results)}\\\\n\\\\n\")\n",
    "        \n",
    "        f.write(\"ğŸ“ˆ RÃ‰SUMÃ‰ DES PERFORMANCES:\\\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\\\n\")\n",
    "        for target_col, metrics in model_metrics.items():\n",
    "            f.write(f\"\\\\nğŸ”¸ {target_col}:\\\\n\")\n",
    "            f.write(f\"   â€¢ RÂ² (coefficient de dÃ©termination): {metrics['RÂ²']:.4f}\\\\n\")\n",
    "            f.write(f\"   â€¢ RMSE (erreur quadratique moyenne): {metrics['RMSE']:.4f}\\\\n\")\n",
    "            f.write(f\"   â€¢ MAE (erreur absolue moyenne): {metrics['MAE']:.4f}\\\\n\")\n",
    "            f.write(f\"   â€¢ MAPE (erreur absolue en pourcentage): {metrics['MAPE']:.2f}%\\\\n\")\n",
    "            \n",
    "            # Ã‰valuation qualitative\n",
    "            if metrics['RÂ²'] >= 0.9:\n",
    "                f.write(f\"   â€¢ Ã‰valuation: Excellent modÃ¨le âœ…\\\\n\")\n",
    "            elif metrics['RÂ²'] >= 0.8:\n",
    "                f.write(f\"   â€¢ Ã‰valuation: Bon modÃ¨le ğŸŸ¢\\\\n\")\n",
    "            elif metrics['RÂ²'] >= 0.6:\n",
    "                f.write(f\"   â€¢ Ã‰valuation: ModÃ¨le acceptable ğŸŸ¡\\\\n\")\n",
    "            else:\n",
    "                f.write(f\"   â€¢ Ã‰valuation: ModÃ¨le Ã  amÃ©liorer ğŸ”´\\\\n\")\n",
    "        \n",
    "        f.write(f\"\\\\n\\\\nğŸ“Š PRÃ‰DICTIONS GÃ‰NÃ‰RÃ‰ES:\\\\n\")\n",
    "        f.write(\"-\" * 25 + \"\\\\n\")\n",
    "        for target_col, results in predictions_results.items():\n",
    "            f.write(f\"\\\\nğŸ”¸ {target_col}:\\\\n\")\n",
    "            f.write(f\"   â€¢ PrÃ©dictions futures: {len(results['future_predictions'])} jours\\\\n\")\n",
    "            f.write(f\"   â€¢ Valeur min prÃ©dite: {results['future_predictions'].min():.2f}\\\\n\")\n",
    "            f.write(f\"   â€¢ Valeur max prÃ©dite: {results['future_predictions'].max():.2f}\\\\n\")\n",
    "            f.write(f\"   â€¢ Valeur moyenne prÃ©dite: {results['future_predictions'].mean():.2f}\\\\n\")\n",
    "    \n",
    "    print(f\"   âœ… Rapport de synthÃ¨se sauvÃ©: {report_file}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "# Fonction de sauvegarde des modÃ¨les (si mode rÃ©-entraÃ®nement)\n",
    "def backup_models(models_dict, backup_dir=\"models_backup\"):\n",
    "    \"\"\"Sauvegarde de sÃ©curitÃ© des modÃ¨les\"\"\"\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"ğŸ’¾ Sauvegarde de sÃ©curitÃ© des modÃ¨les dans: {backup_dir}/\")\n",
    "    \n",
    "    for target_col, model_info in models_dict.items():\n",
    "        # Sauvegarde du modÃ¨le\n",
    "        model_backup_path = os.path.join(backup_dir, f\"{target_col}_LSTM_backup_{timestamp}.h5\")\n",
    "        model_info['model'].save(model_backup_path)\n",
    "        \n",
    "        # Sauvegarde du scaler\n",
    "        scaler_backup_path = os.path.join(backup_dir, f\"{target_col}_scaler_backup_{timestamp}.pkl\")\n",
    "        with open(scaler_backup_path, 'wb') as f:\n",
    "            pickle.dump(model_info['scaler'], f)\n",
    "        \n",
    "        print(f\"   âœ… ModÃ¨le et scaler sauvÃ©s pour: {target_col}\")\n",
    "\n",
    "# ExÃ©cution de la sauvegarde\n",
    "if 'all_predictions' in globals() and 'model_metrics' in globals():\n",
    "    print(\"ğŸ’¾ DÃ©but de la sauvegarde des rÃ©sultats...\")\n",
    "    \n",
    "    # Sauvegarde des rÃ©sultats\n",
    "    results_dir = save_results(all_predictions, model_metrics)\n",
    "    \n",
    "    # Sauvegarde de sÃ©curitÃ© des modÃ¨les si mode rÃ©-entraÃ®nement\n",
    "    if selected_mode == 'retrain' and 'trained_models' in globals():\n",
    "        backup_models(trained_models)\n",
    "    \n",
    "    print(f\"\\\\nğŸ‰ Sauvegarde terminÃ©e avec succÃ¨s!\")\n",
    "    print(f\"ğŸ“ Tous les fichiers sont disponibles dans: {os.path.abspath(results_dir)}\")\n",
    "    \n",
    "    # RÃ©sumÃ© final\n",
    "    print(\"\\\\nğŸ“‹ RÃ‰SUMÃ‰ FINAL:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"ğŸ¯ Mode utilisÃ©: {selected_mode}\")\n",
    "    print(f\"ğŸ“Š Variables prÃ©dites: {len(all_predictions)}\")\n",
    "    print(f\"ğŸ“ˆ PrÃ©dictions futures: 30 jours par variable\")\n",
    "    \n",
    "    # Affichage des meilleures performances\n",
    "    best_model = max(model_metrics.items(), key=lambda x: x[1]['RÂ²'])\n",
    "    worst_model = min(model_metrics.items(), key=lambda x: x[1]['RÂ²'])\n",
    "    \n",
    "    print(f\"ğŸ† Meilleur modÃ¨le: {best_model[0]} (RÂ² = {best_model[1]['RÂ²']:.4f})\")\n",
    "    print(f\"âš ï¸ ModÃ¨le Ã  amÃ©liorer: {worst_model[0]} (RÂ² = {worst_model[1]['RÂ²']:.4f})\")\n",
    "    \n",
    "    avg_r2 = np.mean([metrics['RÂ²'] for metrics in model_metrics.values()])\n",
    "    print(f\"ğŸ“Š RÂ² moyen: {avg_r2:.4f}\")\n",
    "    \n",
    "    if avg_r2 >= 0.8:\n",
    "        print(\"âœ… Performance globale: EXCELLENTE\")\n",
    "    elif avg_r2 >= 0.6:\n",
    "        print(\"ğŸŸ¢ Performance globale: BONNE\")\n",
    "    else:\n",
    "        print(\"ğŸŸ¡ Performance globale: Ã€ AMÃ‰LIORER\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Aucun rÃ©sultat Ã  sauvegarder. ExÃ©cutez d'abord les sections prÃ©cÃ©dentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01c161",
   "metadata": {},
   "source": [
    "## ğŸ¯ 8. Conclusion et Guide d'Utilisation\n",
    "\n",
    "### âœ… FÃ©licitations !\n",
    "\n",
    "Vous avez terminÃ© avec succÃ¨s l'utilisation du systÃ¨me de prÃ©diction Ã©nergÃ©tique LSTM !\n",
    "\n",
    "### ğŸ“‹ RÃ©capitulatif des Ã©tapes accomplies :\n",
    "\n",
    "1. **âš™ï¸ Configuration** - Choix entre modÃ¨les prÃ©-entraÃ®nÃ©s ou rÃ©-entraÃ®nement\n",
    "2. **ğŸ“Š DonnÃ©es** - Chargement et prÃ©paration des donnÃ©es\n",
    "3. **ğŸ¤– ModÃ¨les** - Utilisation ou crÃ©ation des modÃ¨les LSTM\n",
    "4. **ğŸ”® PrÃ©dictions** - GÃ©nÃ©ration des prÃ©dictions futures (30 jours)\n",
    "5. **ğŸ“ˆ Ã‰valuation** - Calcul des mÃ©triques de performance\n",
    "6. **ğŸ’¾ Sauvegarde** - Export des rÃ©sultats en CSV et rapport de synthÃ¨se\n",
    "\n",
    "### ğŸ“ Fichiers gÃ©nÃ©rÃ©s :\n",
    "\n",
    "- **PrÃ©dictions futures** : `[variable]_predictions_futures_[timestamp].csv`\n",
    "- **Ã‰valuations** : `[variable]_evaluation_[timestamp].csv`  \n",
    "- **MÃ©triques** : `metriques_modeles_[timestamp].csv`\n",
    "- **Rapport** : `rapport_synthese_[timestamp].txt`\n",
    "- **ModÃ¨les sauvÃ©s** : Dossiers `models/` et `scalers/`\n",
    "\n",
    "### ğŸ”„ Pour de nouvelles prÃ©dictions :\n",
    "\n",
    "1. **Nouvelles donnÃ©es** : Changez le fichier dans la section 2\n",
    "2. **Nouveaux modÃ¨les** : SÃ©lectionnez \"RÃ©-entraÃ®ner\" dans la section 2\n",
    "3. **ParamÃ¨tres** : Modifiez `SEQUENCE_LENGTH` et `PREDICTION_DAYS` dans la section 5\n",
    "\n",
    "### ğŸ“ Support :\n",
    "\n",
    "Pour toute question ou amÃ©lioration, consultez la documentation du projet ou contactez l'Ã©quipe de dÃ©veloppement.\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ”‹ Merci d'utiliser le SystÃ¨me de PrÃ©diction Ã‰nergÃ©tique LSTM !**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13db17",
   "metadata": {},
   "source": [
    "## ğŸ¤– 4. EntraÃ®nement des ModÃ¨les LSTM\n",
    "\n",
    "Cette section entraÃ®ne les modÃ¨les LSTM pour chaque variable si le mode \"retrain\" est sÃ©lectionnÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a837a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour l'entraÃ®nement\n",
    "SEQUENCE_LENGTH = 30\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Variables Ã  prÃ©dire\n",
    "variables_to_predict = [\n",
    "    'prectotcorr', 'suface_pressure(pa)', 'temp2_ave(c)', \n",
    "    'temp2_max(c)', 'temp2_min(c)', 'total_demand(mw)',\n",
    "    'wind_speed50_ave(ms)', 'wind_speed50_max(ms)', 'wind_speed50_min(ms)'\n",
    "]\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"CrÃ©er un modÃ¨le LSTM optimisÃ©\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(100, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_sequences(data, sequence_length):\n",
    "    \"\"\"PrÃ©parer les sÃ©quences pour l'entraÃ®nement LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Dictionnaires pour stocker les modÃ¨les et scalers\n",
    "trained_models = {}\n",
    "trained_scalers = {}\n",
    "training_history = {}\n",
    "\n",
    "if user_mode == 'retrain':\n",
    "    print(\"ğŸ”„ DÃ©but de l'entraÃ®nement des modÃ¨les personnalisÃ©s...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # EntraÃ®ner un modÃ¨le pour chaque variable\n",
    "    for i, variable in enumerate(variables_to_predict):\n",
    "        print(f\"\\nğŸ¤– EntraÃ®nement du modÃ¨le pour : {variable}\")\n",
    "        print(f\"ğŸ“Š Progression : {i+1}/{len(variables_to_predict)}\")\n",
    "        \n",
    "        if variable in df.columns:\n",
    "            # PrÃ©paration des donnÃ©es\n",
    "            data = df[variable].values.reshape(-1, 1)\n",
    "            \n",
    "            # Normalisation\n",
    "            scaler = MinMaxScaler()\n",
    "            scaled_data = scaler.fit_transform(data)\n",
    "            \n",
    "            # CrÃ©ation des sÃ©quences\n",
    "            X, y = prepare_sequences(scaled_data, SEQUENCE_LENGTH)\n",
    "            \n",
    "            if len(X) > 0:\n",
    "                # Division train/test\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.2, shuffle=False\n",
    "                )\n",
    "                \n",
    "                # CrÃ©ation et entraÃ®nement du modÃ¨le\n",
    "                model = create_lstm_model((SEQUENCE_LENGTH, 1))\n",
    "                \n",
    "                # Callbacks\n",
    "                early_stopping = EarlyStopping(\n",
    "                    monitor='val_loss', \n",
    "                    patience=10, \n",
    "                    restore_best_weights=True\n",
    "                )\n",
    "                \n",
    "                model_checkpoint = ModelCheckpoint(\n",
    "                    f'{MODELS_PATH}{variable}_LSTM.h5',\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True\n",
    "                )\n",
    "                \n",
    "                # EntraÃ®nement\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Sauvegarde\n",
    "                trained_models[variable] = model\n",
    "                trained_scalers[variable] = scaler\n",
    "                training_history[variable] = history.history\n",
    "                \n",
    "                # Sauvegarde du scaler\n",
    "                joblib.dump(scaler, f'{SCALERS_PATH}{variable}_scaler.pkl')\n",
    "                \n",
    "                # Ã‰valuation rapide\n",
    "                train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "                test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "                \n",
    "                print(f\"âœ… {variable} - Train Loss: {train_loss[0]:.4f}, Test Loss: {test_loss[0]:.4f}\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ DonnÃ©es insuffisantes pour {variable}\")\n",
    "        else:\n",
    "            print(f\"âŒ Variable {variable} non trouvÃ©e dans les donnÃ©es\")\n",
    "    \n",
    "    print(\"\\nğŸ‰ EntraÃ®nement terminÃ© pour tous les modÃ¨les!\")\n",
    "    print(f\"ğŸ“ ModÃ¨les sauvegardÃ©s dans : {MODELS_PATH}\")\n",
    "    print(f\"ğŸ“ Scalers sauvegardÃ©s dans : {SCALERS_PATH}\")\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ¯ Utilisation des modÃ¨les prÃ©-entraÃ®nÃ©s...\")\n",
    "    \n",
    "    # Charger les modÃ¨les prÃ©-entraÃ®nÃ©s\n",
    "    for variable in variables_to_predict:\n",
    "        model_path = f'{MODELS_PATH}{variable}_LSTM.h5'\n",
    "        scaler_path = f'{SCALERS_PATH}{variable}_scaler.pkl'\n",
    "        \n",
    "        if os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "            try:\n",
    "                trained_models[variable] = load_model(model_path)\n",
    "                trained_scalers[variable] = joblib.load(scaler_path)\n",
    "                print(f\"âœ… ModÃ¨le chargÃ© pour {variable}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Erreur lors du chargement de {variable}: {e}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ ModÃ¨le prÃ©-entraÃ®nÃ© non trouvÃ© pour {variable}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ModÃ¨les disponibles : {len(trained_models)}\")\n",
    "print(f\"ğŸ”§ Scalers disponibles : {len(trained_scalers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des rÃ©sultats pour l'interface Streamlit\n",
    "def save_results_for_streamlit(predictions_results, output_path=\"../results.csv\"):\n",
    "    \"\"\"Sauvegarde les rÃ©sultats dans le format attendu par Streamlit\"\"\"\n",
    "    \n",
    "    # CrÃ©er un DataFrame avec les rÃ©sultats\n",
    "    results_data = []\n",
    "    \n",
    "    # GÃ©nÃ©rer les dates futures (30 jours Ã  partir d'aujourd'hui)\n",
    "    from datetime import datetime, timedelta\n",
    "    base_date = datetime.now()\n",
    "    \n",
    "    # Prendre le premier modÃ¨le pour dÃ©terminer le nombre de prÃ©dictions\n",
    "    first_key = list(predictions_results.keys())[0]\n",
    "    num_predictions = len(predictions_results[first_key]['future_predictions'])\n",
    "    \n",
    "    for i in range(num_predictions):\n",
    "        date = (base_date + timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Initialiser le dictionnaire de rÃ©sultats pour ce jour\n",
    "        result_row = {'date': date}\n",
    "        \n",
    "        # Ajouter les prÃ©dictions pour chaque variable\n",
    "        for variable, data in predictions_results.items():\n",
    "            if i < len(data['future_predictions']):\n",
    "                result_row[f'{variable}_predit'] = data['future_predictions'][i]\n",
    "        \n",
    "        # Calculer gÃ©nÃ©ration et consommation si les variables appropriÃ©es existent\n",
    "        generation_vars = ['prectotcorr', 'wind_speed50_ave(ms)', 'wind_speed50_max(ms)']\n",
    "        consumption_vars = ['total_demand(mw)', 'temp2_ave(c)', 'temp2_max(c)']\n",
    "        \n",
    "        # Estimation de la gÃ©nÃ©ration (basÃ©e sur les variables mÃ©tÃ©o)\n",
    "        generation = 0\n",
    "        gen_count = 0\n",
    "        for var in generation_vars:\n",
    "            if f'{var}_predit' in result_row:\n",
    "                # Normalisation et pondÃ©ration pour estimation gÃ©nÃ©ration\n",
    "                if 'wind' in var:\n",
    "                    generation += result_row[f'{var}_predit'] * 10  # Facteur Ã©olien\n",
    "                    gen_count += 1\n",
    "                elif 'prectot' in var:\n",
    "                    generation += result_row[f'{var}_predit'] * 5   # Facteur hydroÃ©lectrique\n",
    "                    gen_count += 1\n",
    "        \n",
    "        if gen_count > 0:\n",
    "            generation = generation / gen_count\n",
    "        else:\n",
    "            generation = 100  # Valeur par dÃ©faut\n",
    "        \n",
    "        # Consommation (basÃ©e sur la demande totale ou tempÃ©rature)\n",
    "        consumption = 0\n",
    "        cons_count = 0\n",
    "        for var in consumption_vars:\n",
    "            if f'{var}_predit' in result_row:\n",
    "                if 'demand' in var:\n",
    "                    consumption = result_row[f'{var}_predit']  # Demande directe\n",
    "                    cons_count = 1\n",
    "                    break\n",
    "                elif 'temp' in var:\n",
    "                    # Estimation basÃ©e sur la tempÃ©rature\n",
    "                    temp = result_row[f'{var}_predit']\n",
    "                    consumption += abs(temp - 20) * 5  # Facteur de climatisation/chauffage\n",
    "                    cons_count += 1\n",
    "        \n",
    "        if cons_count == 0:\n",
    "            consumption = 80  # Valeur par dÃ©faut\n",
    "        elif 'demand' not in [var for var in consumption_vars if f'{var}_predit' in result_row]:\n",
    "            consumption = consumption / cons_count\n",
    "        \n",
    "        result_row['generation_predite'] = max(0, generation)\n",
    "        result_row['consommation_predite'] = max(0, consumption)\n",
    "        \n",
    "        results_data.append(result_row)\n",
    "    \n",
    "    # CrÃ©er le DataFrame final\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Sauvegarder en CSV\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… RÃ©sultats sauvegardÃ©s pour Streamlit : {output_path}\")\n",
    "    print(f\"ğŸ“Š {len(results_df)} jours de prÃ©dictions sauvegardÃ©es\")\n",
    "    \n",
    "    # Afficher un aperÃ§u\n",
    "    print(\"\\\\nğŸ“‹ AperÃ§u des rÃ©sultats :\")\n",
    "    display(results_df.head())\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# ExÃ©cuter la sauvegarde si des prÃ©dictions ont Ã©tÃ© gÃ©nÃ©rÃ©es\n",
    "if 'all_predictions' in globals() and all_predictions:\n",
    "    print(\"ğŸ’¾ Sauvegarde des rÃ©sultats pour l'interface Streamlit...\")\n",
    "    streamlit_results = save_results_for_streamlit(all_predictions)\n",
    "    print(\"âœ… Sauvegarde terminÃ©e !\")\n",
    "else:\n",
    "    print(\"âš ï¸ Aucune prÃ©diction trouvÃ©e Ã  sauvegarder\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
