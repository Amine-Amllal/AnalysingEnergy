{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5467ab3c",
   "metadata": {},
   "source": [
    "# üîã LSTM Complet Interface Entra√Ænement - Syst√®me de Pr√©diction √ânerg√©tique\n",
    "\n",
    "## üéØ Objectif\n",
    "Ce notebook permet √† l'utilisateur de choisir entre :\n",
    "1. **Utiliser les mod√®les pr√©-entra√Æn√©s** de la r√©gion Benten \n",
    "2. **R√©-entra√Æner de nouveaux mod√®les** sur ses propres donn√©es\n",
    "\n",
    "Le notebook combine les fonctionnalit√©s de \"LSTM complet\" et \"LSTM Generation\" sans optimisation Optuna pour r√©duire le temps d'ex√©cution.\n",
    "\n",
    "## üìã Structure du Notebook\n",
    "1. **Configuration et choix utilisateur** - S√©lection du mode d'utilisation\n",
    "2. **Chargement et pr√©paration des donn√©es** - Import et preprocessing\n",
    "3. **Mod√®les pr√©-entra√Æn√©s OU Entra√Ænement** - Selon le choix utilisateur\n",
    "4. **Pr√©dictions et √©valuation** - G√©n√©ration des r√©sultats\n",
    "5. **Sauvegarde et export** - Enregistrement des mod√®les et r√©sultats\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01366afe",
   "metadata": {},
   "source": [
    "## üìö 1. Importation des Biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f9e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des biblioth√®ques essentielles\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Preprocessing et m√©triques\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilitaires\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime, timedelta\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "print(\"‚úÖ Toutes les biblioth√®ques ont √©t√© import√©es avec succ√®s!\")\n",
    "print(f\"üîß Version TensorFlow: {tf.__version__}\")\n",
    "print(f\"üìä Version Pandas: {pd.__version__}\")\n",
    "print(f\"üî¢ Version NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa94b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des variables d'environnement\n",
    "import os\n",
    "\n",
    "# Variables configurables depuis l'interface Streamlit\n",
    "LSTM_MODE = os.environ.get('LSTM_MODE', 'pretrained')  # 'pretrained' ou 'retrain'\n",
    "DATA_FILE = os.environ.get('DATA_FILE', 'data.csv')\n",
    "STREAMLIT_MODE = os.environ.get('STREAMLIT_MODE', 'false').lower() == 'true'\n",
    "\n",
    "print(f\"üîß Configuration d'environnement :\")\n",
    "print(f\"   ‚Ä¢ Mode LSTM : {LSTM_MODE}\")\n",
    "print(f\"   ‚Ä¢ Fichier de donn√©es : {DATA_FILE}\")\n",
    "print(f\"   ‚Ä¢ Ex√©cution Streamlit : {STREAMLIT_MODE}\")\n",
    "\n",
    "# Configuration pour compatibilit√© avec l'interface\n",
    "if STREAMLIT_MODE:\n",
    "    print(\"üñ•Ô∏è Mode interface Streamlit activ√© - Configuration automatique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02c6a5",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 2. Configuration et Choix Utilisateur\n",
    "\n",
    "Choisissez le mode d'utilisation :\n",
    "- **Mode 1** : Utiliser les mod√®les pr√©-entra√Æn√©s de la r√©gion Benten\n",
    "- **Mode 2** : R√©-entra√Æner de nouveaux mod√®les sur vos donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des chemins\n",
    "DATA_PATH = \"../Data/\"\n",
    "MODELS_PATH = \"models/\"\n",
    "SCALERS_PATH = \"scalers/\"\n",
    "\n",
    "# Cr√©er les dossiers s'ils n'existent pas\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "os.makedirs(SCALERS_PATH, exist_ok=True)\n",
    "\n",
    "print(\"üîã Syst√®me de Pr√©diction √ânerg√©tique LSTM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Variables globales pour stocker les choix\n",
    "selected_mode = None\n",
    "selected_data_file = None\n",
    "\n",
    "if STREAMLIT_MODE:\n",
    "    # En mode Streamlit, utiliser les variables d'environnement\n",
    "    selected_mode = LSTM_MODE\n",
    "    selected_data_file = DATA_FILE\n",
    "    print(\"üîß Configuration automatique (mode Streamlit):\")\n",
    "    print(f\"üìä Mode s√©lectionn√©: {selected_mode}\")\n",
    "    print(f\"üìÅ Fichier de donn√©es: {selected_data_file}\")\n",
    "    \n",
    "    if selected_mode == 'pretrained':\n",
    "        print(\"üéØ Vous allez utiliser les mod√®les pr√©-entra√Æn√©s de la r√©gion Benten\")\n",
    "    else:\n",
    "        print(\"üîÑ Vous allez r√©-entra√Æner de nouveaux mod√®les\")\n",
    "        \n",
    "else:\n",
    "    # Mode interactif avec widgets\n",
    "    # Interface de choix utilisateur\n",
    "    mode_selection = widgets.RadioButtons(\n",
    "        options=[\n",
    "            ('üéØ Utiliser les mod√®les pr√©-entra√Æn√©s (R√©gion Benten)', 'pretrained'),\n",
    "            ('üîÑ R√©-entra√Æner de nouveaux mod√®les', 'retrain')\n",
    "        ],\n",
    "        value='pretrained',\n",
    "        description='Mode:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Widget de s√©lection du fichier de donn√©es\n",
    "    data_file_selection = widgets.Dropdown(\n",
    "        options=['data.csv', 'train_data.csv', 'test_data.csv', 'uploaded_test_data.csv'],\n",
    "        value='data.csv',\n",
    "        description='Fichier de donn√©es:',\n",
    "        disabled=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Bouton pour confirmer la s√©lection\n",
    "    confirm_button = widgets.Button(\n",
    "        description=\"‚úÖ Confirmer la s√©lection\",\n",
    "        button_style='success',\n",
    "        tooltip='Cliquez pour confirmer votre choix'\n",
    "    )\n",
    "\n",
    "    def on_confirm_clicked(b):\n",
    "        global selected_mode, selected_data_file\n",
    "        selected_mode = mode_selection.value\n",
    "        selected_data_file = data_file_selection.value\n",
    "        \n",
    "        clear_output()\n",
    "        print(\"‚úÖ Configuration confirm√©e!\")\n",
    "        print(f\"üìä Mode s√©lectionn√©: {selected_mode}\")\n",
    "        print(f\"üìÅ Fichier de donn√©es: {selected_data_file}\")\n",
    "        \n",
    "        if selected_mode == 'pretrained':\n",
    "            print(\"üéØ Vous allez utiliser les mod√®les pr√©-entra√Æn√©s de la r√©gion Benten\")\n",
    "        else:\n",
    "            print(\"üîÑ Vous allez r√©-entra√Æner de nouveaux mod√®les\")\n",
    "\n",
    "    confirm_button.on_click(on_confirm_clicked)\n",
    "\n",
    "    # Affichage de l'interface\n",
    "    print(\"üîß Configuration manuelle (mode interactif):\")\n",
    "    display(mode_selection)\n",
    "    display(data_file_selection)\n",
    "    display(confirm_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dc71b3",
   "metadata": {},
   "source": [
    "## üìä 3. Chargement et Pr√©paration des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de chargement des donn√©es\n",
    "def load_and_prepare_data(file_name):\n",
    "    \"\"\"Charge et pr√©pare les donn√©es pour l'entra√Ænement LSTM\"\"\"\n",
    "    try:\n",
    "        # Chargement des donn√©es\n",
    "        data_path = os.path.join(DATA_PATH, file_name)\n",
    "        data = pd.read_csv(data_path)\n",
    "        \n",
    "        print(f\"‚úÖ Donn√©es charg√©es depuis: {data_path}\")\n",
    "        print(f\"üìä Forme des donn√©es: {data.shape}\")\n",
    "        print(f\"üìã Colonnes disponibles: {list(data.columns)}\")\n",
    "        \n",
    "        # V√©rification de la colonne date\n",
    "        if 'date' in data.columns:\n",
    "            data['date'] = pd.to_datetime(data['date'])\n",
    "            data = data.sort_values('date')\n",
    "            print(\"üìÖ Colonne date format√©e et donn√©es tri√©es\")\n",
    "        \n",
    "        # Identification des colonnes de pr√©diction\n",
    "        prediction_columns = [col for col in data.columns if col != 'date']\n",
    "        print(f\"üéØ Colonnes de pr√©diction: {prediction_columns}\")\n",
    "        \n",
    "        # V√©rification des valeurs manquantes\n",
    "        missing_values = data.isnull().sum()\n",
    "        if missing_values.sum() > 0:\n",
    "            print(\"‚ö†Ô∏è Valeurs manquantes d√©tect√©es:\")\n",
    "            print(missing_values[missing_values > 0])\n",
    "            data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "            print(\"‚úÖ Valeurs manquantes corrig√©es\")\n",
    "        \n",
    "        return data, prediction_columns\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du chargement des donn√©es: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# D√©terminer le fichier de donn√©es √† utiliser\n",
    "if STREAMLIT_MODE:\n",
    "    # En mode Streamlit, utiliser le fichier t√©l√©vers√©\n",
    "    data_file_to_use = selected_data_file if 'selected_data_file' in globals() else DATA_FILE\n",
    "    print(f\"üîß Mode Streamlit: Utilisation du fichier {data_file_to_use}\")\n",
    "else:\n",
    "    # En mode interactif, utiliser la s√©lection utilisateur ou fichier par d√©faut\n",
    "    data_file_to_use = selected_data_file if 'selected_data_file' in globals() and selected_data_file else 'data.csv'\n",
    "    print(f\"üîß Mode interactif: Utilisation du fichier {data_file_to_use}\")\n",
    "\n",
    "# Chargement des donn√©es\n",
    "data, prediction_columns = load_and_prepare_data(data_file_to_use)\n",
    "\n",
    "if data is not None:\n",
    "    print(\"\\nüìà Aper√ßu des donn√©es:\")\n",
    "    display(data.head())\n",
    "    \n",
    "    print(\"\\nüìä Statistiques descriptives:\")\n",
    "    display(data.describe())\n",
    "    \n",
    "    # Visualisation des donn√©es (seulement en mode non-Streamlit pour √©viter les conflits)\n",
    "    if not STREAMLIT_MODE:\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Graphique temporel si colonne date disponible\n",
    "        if 'date' in data.columns:\n",
    "            for i, col in enumerate(prediction_columns[:4]):  # Limite √† 4 colonnes pour la lisibilit√©\n",
    "                plt.subplot(2, 2, i+1)\n",
    "                plt.plot(data['date'], data[col])\n",
    "                plt.title(f'√âvolution de {col}')\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel(col)\n",
    "                plt.xticks(rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"üìä Visualisations d√©sactiv√©es en mode Streamlit\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Impossible de charger les donn√©es. V√©rifiez le nom du fichier.\")\n",
    "    if STREAMLIT_MODE:\n",
    "        raise FileNotFoundError(f\"Fichier de donn√©es non trouv√©: {data_file_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cd74a",
   "metadata": {},
   "source": [
    "## üéØ 4. Choix entre Mod√®les Pr√©-entra√Æn√©s et R√©-entra√Ænement\n",
    "\n",
    "Cette section ex√©cute diff√©rents processus selon votre choix :\n",
    "- **Mod√®les pr√©-entra√Æn√©s** : Chargement des mod√®les de la r√©gion Benten\n",
    "- **R√©-entra√Ænement** : Cr√©ation et entra√Ænement de nouveaux mod√®les"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03103f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions utilitaires pour le preprocessing\n",
    "def create_sequences(data, target_col, sequence_length=60):\n",
    "    \"\"\"Cr√©e des s√©quences pour l'entra√Ænement LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i])\n",
    "        y.append(data[i, target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def prepare_data_for_training(data, target_columns, sequence_length=60, test_size=0.2):\n",
    "    \"\"\"Pr√©pare les donn√©es pour l'entra√Ænement\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for target_col in target_columns:\n",
    "        print(f\"\\nüéØ Pr√©paration des donn√©es pour: {target_col}\")\n",
    "        \n",
    "        # S√©lection des features (toutes les colonnes num√©riques)\n",
    "        feature_columns = [col for col in data.columns if col != 'date' and data[col].dtype in ['float64', 'int64']]\n",
    "        features_data = data[feature_columns].values\n",
    "        \n",
    "        # Normalisation\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(features_data)\n",
    "        \n",
    "        # Index de la colonne cible\n",
    "        target_idx = feature_columns.index(target_col)\n",
    "        \n",
    "        # Cr√©ation des s√©quences\n",
    "        X, y = create_sequences(scaled_data, target_idx, sequence_length)\n",
    "        \n",
    "        # Division train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, shuffle=False\n",
    "        )\n",
    "        \n",
    "        results[target_col] = {\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test,\n",
    "            'scaler': scaler,\n",
    "            'feature_columns': feature_columns\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ Donn√©es pr√©par√©es - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Fonction pour cr√©er un mod√®le LSTM\n",
    "def create_lstm_model(input_shape, neurons=[50, 50], dropout_rate=0.2):\n",
    "    \"\"\"Cr√©e un mod√®le LSTM avec architecture simple\"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Premi√®re couche LSTM\n",
    "    model.add(LSTM(neurons[0], return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Deuxi√®me couche LSTM\n",
    "    model.add(LSTM(neurons[1], return_sequences=False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Couche de sortie\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # Compilation\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# V√©rification des variables d'environnement pour compatibilit√© Streamlit\n",
    "if STREAMLIT_MODE:\n",
    "    # En mode Streamlit, utiliser les variables d'environnement\n",
    "    selected_mode = LSTM_MODE\n",
    "    selected_data_file = DATA_FILE\n",
    "    print(f\"üîß Mode Streamlit d√©tect√© - Configuration automatique:\")\n",
    "    print(f\"   ‚Ä¢ Mode: {selected_mode}\")\n",
    "    print(f\"   ‚Ä¢ Fichier: {selected_data_file}\")\n",
    "\n",
    "# Ex√©cution selon le mode choisi\n",
    "if 'selected_mode' in globals() and selected_mode and data is not None:\n",
    "    \n",
    "    if selected_mode == 'pretrained':\n",
    "        print(\"üéØ Mode: Utilisation des mod√®les pr√©-entra√Æn√©s\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # V√©rification de l'existence des mod√®les pr√©-entra√Æn√©s\n",
    "        pretrained_models = {}\n",
    "        available_models = []\n",
    "        \n",
    "        for col in prediction_columns:\n",
    "            model_path = os.path.join(MODELS_PATH, f\"{col}_LSTM.h5\")\n",
    "            scaler_path = os.path.join(SCALERS_PATH, f\"{col}_scaler.pkl\")\n",
    "            \n",
    "            if os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "                try:\n",
    "                    model = load_model(model_path)\n",
    "                    with open(scaler_path, 'rb') as f:\n",
    "                        scaler = pickle.load(f)\n",
    "                    \n",
    "                    pretrained_models[col] = {'model': model, 'scaler': scaler}\n",
    "                    available_models.append(col)\n",
    "                    print(f\"‚úÖ Mod√®le pr√©-entra√Æn√© charg√© pour: {col}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Erreur lors du chargement du mod√®le {col}: {str(e)}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Mod√®le pr√©-entra√Æn√© non trouv√© pour: {col}\")\n",
    "        \n",
    "        if available_models:\n",
    "            print(f\"\\nüéâ {len(available_models)} mod√®les pr√©-entra√Æn√©s disponibles!\")\n",
    "            models_ready = True\n",
    "        else:\n",
    "            print(\"‚ùå Aucun mod√®le pr√©-entra√Æn√© trouv√©. Passez au mode r√©-entra√Ænement.\")\n",
    "            models_ready = False\n",
    "    \n",
    "    else:  # Mode r√©-entra√Ænement\n",
    "        print(\"üîÑ Mode: R√©-entra√Ænement de nouveaux mod√®les\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Pr√©paration des donn√©es pour l'entra√Ænement\n",
    "        training_data = prepare_data_for_training(data, prediction_columns)\n",
    "        trained_models = {}\n",
    "        \n",
    "        for target_col in prediction_columns:\n",
    "            print(f\"\\nüöÄ Entra√Ænement du mod√®le pour: {target_col}\")\n",
    "            \n",
    "            # R√©cup√©ration des donn√©es pr√©par√©es\n",
    "            data_dict = training_data[target_col]\n",
    "            X_train, y_train = data_dict['X_train'], data_dict['y_train']\n",
    "            X_test, y_test = data_dict['X_test'], data_dict['y_test']\n",
    "            \n",
    "            # Cr√©ation du mod√®le\n",
    "            input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "            model = create_lstm_model(input_shape)\n",
    "            \n",
    "            print(f\"üìä Architecture du mod√®le: {model.summary()}\")\n",
    "            \n",
    "            # Callbacks\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            \n",
    "            # Entra√Ænement\n",
    "            print(\"üîÑ D√©but de l'entra√Ænement...\")\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=50,  # Nombre d'√©poques r√©duit pour √©conomiser du temps\n",
    "                batch_size=32,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Sauvegarde du mod√®le et du scaler\n",
    "            model_path = os.path.join(MODELS_PATH, f\"{target_col}_LSTM.h5\")\n",
    "            scaler_path = os.path.join(SCALERS_PATH, f\"{target_col}_scaler.pkl\")\n",
    "            \n",
    "            model.save(model_path)\n",
    "            with open(scaler_path, 'wb') as f:\n",
    "                pickle.dump(data_dict['scaler'], f)\n",
    "            \n",
    "            trained_models[target_col] = {\n",
    "                'model': model,\n",
    "                'scaler': data_dict['scaler'],\n",
    "                'history': history,\n",
    "                'test_data': (X_test, y_test)\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Mod√®le entra√Æn√© et sauvegard√© pour: {target_col}\")\n",
    "            \n",
    "            # Affichage de la courbe d'apprentissage\n",
    "            plt.figure(figsize=(12, 4))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(history.history['loss'], label='Train Loss')\n",
    "            plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "            plt.title(f'Courbe d\\'apprentissage - {target_col}')\n",
    "            plt.xlabel('√âpoque')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(history.history['mae'], label='Train MAE')\n",
    "            plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "            plt.title(f'Erreur absolue moyenne - {target_col}')\n",
    "            plt.xlabel('√âpoque')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        print(f\"\\nüéâ Entra√Ænement termin√© pour {len(trained_models)} mod√®les!\")\n",
    "        models_ready = True\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Veuillez d'abord confirmer votre s√©lection et charger les donn√©es.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc77def5",
   "metadata": {},
   "source": [
    "## üîÆ 5. G√©n√©ration des Pr√©dictions\n",
    "\n",
    "Cette section utilise les mod√®les (pr√©-entra√Æn√©s ou nouvellement entra√Æn√©s) pour g√©n√©rer des pr√©dictions sur les donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac622a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour g√©n√©rer des pr√©dictions\n",
    "def generate_predictions(models_dict, data, sequence_length=60, prediction_days=30):\n",
    "    \"\"\"G√©n√®re des pr√©dictions avec les mod√®les disponibles\"\"\"\n",
    "    predictions_results = {}\n",
    "    \n",
    "    for target_col, model_info in models_dict.items():\n",
    "        print(f\"\\nüîÆ G√©n√©ration des pr√©dictions pour: {target_col}\")\n",
    "        \n",
    "        model = model_info['model']\n",
    "        scaler = model_info['scaler']\n",
    "        \n",
    "        # Pr√©paration des donn√©es pour pr√©diction\n",
    "        feature_columns = [col for col in data.columns if col != 'date' and data[col].dtype in ['float64', 'int64']]\n",
    "        features_data = data[feature_columns].values\n",
    "        \n",
    "        # Normalisation avec le scaler du mod√®le\n",
    "        scaled_data = scaler.transform(features_data)\n",
    "        \n",
    "        # Index de la colonne cible\n",
    "        target_idx = feature_columns.index(target_col)\n",
    "        \n",
    "        # Prendre les derni√®res s√©quences pour commencer les pr√©dictions\n",
    "        last_sequence = scaled_data[-sequence_length:]\n",
    "        \n",
    "        # G√©n√©ration des pr√©dictions futures\n",
    "        future_predictions = []\n",
    "        current_sequence = last_sequence.copy()\n",
    "        \n",
    "        for _ in range(prediction_days):\n",
    "            # Reshape pour le mod√®le LSTM\n",
    "            input_seq = current_sequence.reshape(1, sequence_length, len(feature_columns))\n",
    "            \n",
    "            # Pr√©diction\n",
    "            pred = model.predict(input_seq, verbose=0)[0, 0]\n",
    "            future_predictions.append(pred)\n",
    "            \n",
    "            # Mettre √† jour la s√©quence pour la prochaine pr√©diction\n",
    "            new_row = current_sequence[-1].copy()\n",
    "            new_row[target_idx] = pred\n",
    "            \n",
    "            # D√©caler la s√©quence\n",
    "            current_sequence = np.vstack([current_sequence[1:], new_row])\n",
    "        \n",
    "        # D√©normalisation des pr√©dictions\n",
    "        # Cr√©er un array temporaire pour la d√©normalisation\n",
    "        temp_array = np.zeros((len(future_predictions), len(feature_columns)))\n",
    "        temp_array[:, target_idx] = future_predictions\n",
    "        denormalized = scaler.inverse_transform(temp_array)\n",
    "        final_predictions = denormalized[:, target_idx]\n",
    "        \n",
    "        # Pr√©dictions sur les donn√©es historiques pour √©valuation\n",
    "        historical_predictions = []\n",
    "        for i in range(sequence_length, len(scaled_data)):\n",
    "            input_seq = scaled_data[i-sequence_length:i].reshape(1, sequence_length, len(feature_columns))\n",
    "            pred = model.predict(input_seq, verbose=0)[0, 0]\n",
    "            historical_predictions.append(pred)\n",
    "        \n",
    "        # D√©normalisation des pr√©dictions historiques\n",
    "        temp_hist = np.zeros((len(historical_predictions), len(feature_columns)))\n",
    "        temp_hist[:, target_idx] = historical_predictions\n",
    "        denorm_hist = scaler.inverse_transform(temp_hist)\n",
    "        final_hist_predictions = denorm_hist[:, target_idx]\n",
    "        \n",
    "        # Stockage des r√©sultats\n",
    "        predictions_results[target_col] = {\n",
    "            'future_predictions': final_predictions,\n",
    "            'historical_predictions': final_hist_predictions,\n",
    "            'actual_values': data[target_col].values[sequence_length:],\n",
    "            'feature_columns': feature_columns,\n",
    "            'dates': data['date'].values if 'date' in data.columns else None\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {len(final_predictions)} pr√©dictions futures g√©n√©r√©es\")\n",
    "        print(f\"üìä {len(final_hist_predictions)} pr√©dictions historiques g√©n√©r√©es\")\n",
    "    \n",
    "    return predictions_results\n",
    "\n",
    "# G√©n√©ration des pr√©dictions selon le mode\n",
    "if 'models_ready' in globals() and models_ready:\n",
    "    print(\"üîÆ G√©n√©ration des pr√©dictions en cours...\")\n",
    "    \n",
    "    # S√©lection des mod√®les selon le mode\n",
    "    if selected_mode == 'pretrained':\n",
    "        active_models = pretrained_models\n",
    "        print(\"üìä Utilisation des mod√®les pr√©-entra√Æn√©s\")\n",
    "    else:\n",
    "        active_models = trained_models\n",
    "        print(\"üìä Utilisation des mod√®les nouvellement entra√Æn√©s\")\n",
    "    \n",
    "    # Param√®tres de pr√©diction\n",
    "    SEQUENCE_LENGTH = 60\n",
    "    PREDICTION_DAYS = 30\n",
    "    \n",
    "    print(f\"‚öôÔ∏è Param√®tres: S√©quence={SEQUENCE_LENGTH}, Pr√©dictions futures={PREDICTION_DAYS} jours\")\n",
    "    \n",
    "    # G√©n√©ration des pr√©dictions\n",
    "    all_predictions = generate_predictions(\n",
    "        active_models, \n",
    "        data, \n",
    "        sequence_length=SEQUENCE_LENGTH, \n",
    "        prediction_days=PREDICTION_DAYS\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüéâ Pr√©dictions g√©n√©r√©es pour {len(all_predictions)} variables!\")\n",
    "    \n",
    "    # Affichage des r√©sultats pour chaque variable\n",
    "    for target_col, results in all_predictions.items():\n",
    "        print(f\"\\nüìà R√©sultats pour {target_col}:\")\n",
    "        print(f\"   ‚Ä¢ Pr√©dictions futures: {len(results['future_predictions'])} valeurs\")\n",
    "        print(f\"   ‚Ä¢ Pr√©dictions historiques: {len(results['historical_predictions'])} valeurs\")\n",
    "        print(f\"   ‚Ä¢ Valeurs min/max futures: {results['future_predictions'].min():.2f} / {results['future_predictions'].max():.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Les mod√®les ne sont pas pr√™ts. Ex√©cutez d'abord les cellules pr√©c√©dentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da05856",
   "metadata": {},
   "source": [
    "## üìä 6. √âvaluation des Mod√®les\n",
    "\n",
    "Cette section √©value les performances des mod√®les en calculant diff√©rentes m√©triques et en g√©n√©rant des visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c1c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'√©valuation des mod√®les\n",
    "def evaluate_model_performance(predictions_results):\n",
    "    \"\"\"√âvalue les performances des mod√®les avec diff√©rentes m√©triques\"\"\"\n",
    "    evaluation_results = {}\n",
    "    \n",
    "    print(\"üìä √âvaluation des performances des mod√®les\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for target_col, results in predictions_results.items():\n",
    "        print(f\"\\nüéØ √âvaluation pour: {target_col}\")\n",
    "        \n",
    "        actual = results['actual_values']\n",
    "        predicted = results['historical_predictions']\n",
    "        \n",
    "        # Calcul des m√©triques\n",
    "        mse = mean_squared_error(actual, predicted)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(actual, predicted)\n",
    "        r2 = r2_score(actual, predicted)\n",
    "        \n",
    "        # MAPE (Mean Absolute Percentage Error)\n",
    "        mape = np.mean(np.abs((actual - predicted) / actual)) * 100\n",
    "        \n",
    "        # Stockage des m√©triques\n",
    "        metrics = {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R¬≤': r2,\n",
    "            'MAPE': mape\n",
    "        }\n",
    "        \n",
    "        evaluation_results[target_col] = metrics\n",
    "        \n",
    "        # Affichage des m√©triques\n",
    "        print(f\"   üìà MSE (Mean Squared Error): {mse:.4f}\")\n",
    "        print(f\"   üìà RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "        print(f\"   üìà MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "        print(f\"   üìà R¬≤ (Coefficient de d√©termination): {r2:.4f}\")\n",
    "        print(f\"   üìà MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "        \n",
    "        # Interpr√©tation du R¬≤\n",
    "        if r2 >= 0.9:\n",
    "            print(\"   ‚úÖ Excellent mod√®le (R¬≤ ‚â• 0.9)\")\n",
    "        elif r2 >= 0.8:\n",
    "            print(\"   üü¢ Bon mod√®le (R¬≤ ‚â• 0.8)\")\n",
    "        elif r2 >= 0.6:\n",
    "            print(\"   üü° Mod√®le acceptable (R¬≤ ‚â• 0.6)\")\n",
    "        else:\n",
    "            print(\"   üî¥ Mod√®le √† am√©liorer (R¬≤ < 0.6)\")\n",
    "    \n",
    "    return evaluation_results\n",
    "\n",
    "# Fonction de visualisation des r√©sultats\n",
    "def visualize_predictions(predictions_results, max_points=1000):\n",
    "    \"\"\"Visualise les pr√©dictions vs valeurs r√©elles\"\"\"\n",
    "    n_models = len(predictions_results)\n",
    "    \n",
    "    # Calcul du nombre de lignes et colonnes pour les sous-graphiques\n",
    "    cols = min(2, n_models)\n",
    "    rows = (n_models + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * rows))\n",
    "    \n",
    "    for idx, (target_col, results) in enumerate(predictions_results.items()):\n",
    "        # Graphique 1: Comparaison pr√©dictions vs r√©alit√©\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        \n",
    "        actual = results['actual_values']\n",
    "        predicted = results['historical_predictions']\n",
    "        \n",
    "        # Limitation du nombre de points pour la lisibilit√©\n",
    "        if len(actual) > max_points:\n",
    "            step = len(actual) // max_points\n",
    "            actual_plot = actual[::step]\n",
    "            predicted_plot = predicted[::step]\n",
    "        else:\n",
    "            actual_plot = actual\n",
    "            predicted_plot = predicted\n",
    "        \n",
    "        plt.plot(actual_plot, label='Valeurs r√©elles', alpha=0.7, linewidth=1)\n",
    "        plt.plot(predicted_plot, label='Pr√©dictions', alpha=0.7, linewidth=1)\n",
    "        plt.title(f'Pr√©dictions vs R√©alit√© - {target_col}')\n",
    "        plt.xlabel('√âchantillons')\n",
    "        plt.ylabel('Valeurs')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Graphique des pr√©dictions futures\n",
    "    plt.figure(figsize=(15, 5 * rows))\n",
    "    \n",
    "    for idx, (target_col, results) in enumerate(predictions_results.items()):\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        \n",
    "        future_pred = results['future_predictions']\n",
    "        \n",
    "        # Affichage des derni√®res valeurs historiques pour contexte\n",
    "        if len(results['actual_values']) > 0:\n",
    "            last_actual = results['actual_values'][-30:]  # Derniers 30 points\n",
    "            x_hist = range(-len(last_actual), 0)\n",
    "            plt.plot(x_hist, last_actual, label='Historique r√©cent', color='blue', alpha=0.7)\n",
    "        \n",
    "        # Pr√©dictions futures\n",
    "        x_future = range(0, len(future_pred))\n",
    "        plt.plot(x_future, future_pred, label='Pr√©dictions futures', color='red', marker='o', markersize=3)\n",
    "        \n",
    "        plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5, label='D√©but des pr√©dictions')\n",
    "        plt.title(f'Pr√©dictions futures - {target_col}')\n",
    "        plt.xlabel('Jours')\n",
    "        plt.ylabel('Valeurs')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ex√©cution de l'√©valuation\n",
    "if 'all_predictions' in globals() and all_predictions:\n",
    "    print(\"üìä D√©but de l'√©valuation des mod√®les...\")\n",
    "    \n",
    "    # √âvaluation des performances\n",
    "    model_metrics = evaluate_model_performance(all_predictions)\n",
    "    \n",
    "    # Cr√©ation d'un DataFrame r√©capitulatif\n",
    "    metrics_df = pd.DataFrame(model_metrics).T\n",
    "    print(\"\\nüìã R√©capitulatif des m√©triques:\")\n",
    "    display(metrics_df.round(4))\n",
    "    \n",
    "    # Visualisation des r√©sultats\n",
    "    print(\"\\nüìà G√©n√©ration des graphiques...\")\n",
    "    visualize_predictions(all_predictions)\n",
    "    \n",
    "    # Graphique en barres des m√©triques R¬≤\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    r2_values = [metrics['R¬≤'] for metrics in model_metrics.values()]\n",
    "    model_names = list(model_metrics.keys())\n",
    "    \n",
    "    colors = ['green' if r2 >= 0.8 else 'orange' if r2 >= 0.6 else 'red' for r2 in r2_values]\n",
    "    \n",
    "    plt.bar(model_names, r2_values, color=colors, alpha=0.7)\n",
    "    plt.title('Coefficient de d√©termination (R¬≤) par mod√®le')\n",
    "    plt.ylabel('R¬≤')\n",
    "    plt.xlabel('Variables')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ligne de r√©f√©rence pour un bon mod√®le\n",
    "    plt.axhline(y=0.8, color='red', linestyle='--', alpha=0.5, label='Seuil bon mod√®le (0.8)')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úÖ √âvaluation termin√©e!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune pr√©diction trouv√©e. Ex√©cutez d'abord la section de g√©n√©ration des pr√©dictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db56b5d7",
   "metadata": {},
   "source": [
    "## üíæ 7. Sauvegarde et Export des R√©sultats\n",
    "\n",
    "Cette section sauvegarde les mod√®les, les m√©triques et exporte les r√©sultats dans diff√©rents formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02712177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de sauvegarde des r√©sultats\n",
    "def save_results(predictions_results, model_metrics, output_dir=\"results\"):\n",
    "    \"\"\"Sauvegarde les r√©sultats dans diff√©rents formats\"\"\"\n",
    "    \n",
    "    # Cr√©er le dossier de r√©sultats\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"üíæ Sauvegarde des r√©sultats dans: {output_dir}/\")\n",
    "    \n",
    "    # 1. Sauvegarde des pr√©dictions en CSV\n",
    "    for target_col, results in predictions_results.items():\n",
    "        # Pr√©dictions futures\n",
    "        future_df = pd.DataFrame({\n",
    "            'jour': range(1, len(results['future_predictions']) + 1),\n",
    "            'prediction': results['future_predictions']\n",
    "        })\n",
    "        future_file = os.path.join(output_dir, f\"{target_col}_predictions_futures_{timestamp}.csv\")\n",
    "        future_df.to_csv(future_file, index=False)\n",
    "        print(f\"   ‚úÖ Pr√©dictions futures sauv√©es: {future_file}\")\n",
    "        \n",
    "        # Pr√©dictions historiques vs r√©alit√©\n",
    "        historical_df = pd.DataFrame({\n",
    "            'valeur_reelle': results['actual_values'],\n",
    "            'prediction': results['historical_predictions'],\n",
    "            'erreur': results['actual_values'] - results['historical_predictions']\n",
    "        })\n",
    "        historical_file = os.path.join(output_dir, f\"{target_col}_evaluation_{timestamp}.csv\")\n",
    "        historical_df.to_csv(historical_file, index=False)\n",
    "        print(f\"   ‚úÖ √âvaluation historique sauv√©e: {historical_file}\")\n",
    "    \n",
    "    # 2. Sauvegarde des m√©triques\n",
    "    metrics_df = pd.DataFrame(model_metrics).T\n",
    "    metrics_file = os.path.join(output_dir, f\"metriques_modeles_{timestamp}.csv\")\n",
    "    metrics_df.to_csv(metrics_file)\n",
    "    print(f\"   ‚úÖ M√©triques sauv√©es: {metrics_file}\")\n",
    "    \n",
    "    # 3. Rapport de synth√®se\n",
    "    report_file = os.path.join(output_dir, f\"rapport_synthese_{timestamp}.txt\")\n",
    "    with open(report_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"üîã RAPPORT DE SYNTH√àSE - SYST√àME DE PR√âDICTION √âNERG√âTIQUE\\\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\\\n\\\\n\")\n",
    "        f.write(f\"üìÖ Date de g√©n√©ration: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\\\n\")\n",
    "        f.write(f\"üìä Mode utilis√©: {selected_mode}\\\\n\")\n",
    "        f.write(f\"üìÅ Fichier de donn√©es: {selected_data_file}\\\\n\")\n",
    "        f.write(f\"üéØ Nombre de variables pr√©dites: {len(predictions_results)}\\\\n\\\\n\")\n",
    "        \n",
    "        f.write(\"üìà R√âSUM√â DES PERFORMANCES:\\\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\\\n\")\n",
    "        for target_col, metrics in model_metrics.items():\n",
    "            f.write(f\"\\\\nüî∏ {target_col}:\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ R¬≤ (coefficient de d√©termination): {metrics['R¬≤']:.4f}\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ RMSE (erreur quadratique moyenne): {metrics['RMSE']:.4f}\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ MAE (erreur absolue moyenne): {metrics['MAE']:.4f}\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ MAPE (erreur absolue en pourcentage): {metrics['MAPE']:.2f}%\\\\n\")\n",
    "            \n",
    "            # √âvaluation qualitative\n",
    "            if metrics['R¬≤'] >= 0.9:\n",
    "                f.write(f\"   ‚Ä¢ √âvaluation: Excellent mod√®le ‚úÖ\\\\n\")\n",
    "            elif metrics['R¬≤'] >= 0.8:\n",
    "                f.write(f\"   ‚Ä¢ √âvaluation: Bon mod√®le üü¢\\\\n\")\n",
    "            elif metrics['R¬≤'] >= 0.6:\n",
    "                f.write(f\"   ‚Ä¢ √âvaluation: Mod√®le acceptable üü°\\\\n\")\n",
    "            else:\n",
    "                f.write(f\"   ‚Ä¢ √âvaluation: Mod√®le √† am√©liorer üî¥\\\\n\")\n",
    "        \n",
    "        f.write(f\"\\\\n\\\\nüìä PR√âDICTIONS G√âN√âR√âES:\\\\n\")\n",
    "        f.write(\"-\" * 25 + \"\\\\n\")\n",
    "        for target_col, results in predictions_results.items():\n",
    "            f.write(f\"\\\\nüî∏ {target_col}:\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ Pr√©dictions futures: {len(results['future_predictions'])} jours\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ Valeur min pr√©dite: {results['future_predictions'].min():.2f}\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ Valeur max pr√©dite: {results['future_predictions'].max():.2f}\\\\n\")\n",
    "            f.write(f\"   ‚Ä¢ Valeur moyenne pr√©dite: {results['future_predictions'].mean():.2f}\\\\n\")\n",
    "    \n",
    "    print(f\"   ‚úÖ Rapport de synth√®se sauv√©: {report_file}\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "# Fonction de sauvegarde des mod√®les (si mode r√©-entra√Ænement)\n",
    "def backup_models(models_dict, backup_dir=\"models_backup\"):\n",
    "    \"\"\"Sauvegarde de s√©curit√© des mod√®les\"\"\"\n",
    "    os.makedirs(backup_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"üíæ Sauvegarde de s√©curit√© des mod√®les dans: {backup_dir}/\")\n",
    "    \n",
    "    for target_col, model_info in models_dict.items():\n",
    "        # Sauvegarde du mod√®le\n",
    "        model_backup_path = os.path.join(backup_dir, f\"{target_col}_LSTM_backup_{timestamp}.h5\")\n",
    "        model_info['model'].save(model_backup_path)\n",
    "        \n",
    "        # Sauvegarde du scaler\n",
    "        scaler_backup_path = os.path.join(backup_dir, f\"{target_col}_scaler_backup_{timestamp}.pkl\")\n",
    "        with open(scaler_backup_path, 'wb') as f:\n",
    "            pickle.dump(model_info['scaler'], f)\n",
    "        \n",
    "        print(f\"   ‚úÖ Mod√®le et scaler sauv√©s pour: {target_col}\")\n",
    "\n",
    "# Ex√©cution de la sauvegarde\n",
    "if 'all_predictions' in globals() and 'model_metrics' in globals():\n",
    "    print(\"üíæ D√©but de la sauvegarde des r√©sultats...\")\n",
    "    \n",
    "    # Sauvegarde des r√©sultats\n",
    "    results_dir = save_results(all_predictions, model_metrics)\n",
    "    \n",
    "    # Sauvegarde de s√©curit√© des mod√®les si mode r√©-entra√Ænement\n",
    "    if selected_mode == 'retrain' and 'trained_models' in globals():\n",
    "        backup_models(trained_models)\n",
    "    \n",
    "    print(f\"\\\\nüéâ Sauvegarde termin√©e avec succ√®s!\")\n",
    "    print(f\"üìÅ Tous les fichiers sont disponibles dans: {os.path.abspath(results_dir)}\")\n",
    "    \n",
    "    # R√©sum√© final\n",
    "    print(\"\\\\nüìã R√âSUM√â FINAL:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üéØ Mode utilis√©: {selected_mode}\")\n",
    "    print(f\"üìä Variables pr√©dites: {len(all_predictions)}\")\n",
    "    print(f\"üìà Pr√©dictions futures: 30 jours par variable\")\n",
    "    \n",
    "    # Affichage des meilleures performances\n",
    "    best_model = max(model_metrics.items(), key=lambda x: x[1]['R¬≤'])\n",
    "    worst_model = min(model_metrics.items(), key=lambda x: x[1]['R¬≤'])\n",
    "    \n",
    "    print(f\"üèÜ Meilleur mod√®le: {best_model[0]} (R¬≤ = {best_model[1]['R¬≤']:.4f})\")\n",
    "    print(f\"‚ö†Ô∏è Mod√®le √† am√©liorer: {worst_model[0]} (R¬≤ = {worst_model[1]['R¬≤']:.4f})\")\n",
    "    \n",
    "    avg_r2 = np.mean([metrics['R¬≤'] for metrics in model_metrics.values()])\n",
    "    print(f\"üìä R¬≤ moyen: {avg_r2:.4f}\")\n",
    "    \n",
    "    if avg_r2 >= 0.8:\n",
    "        print(\"‚úÖ Performance globale: EXCELLENTE\")\n",
    "    elif avg_r2 >= 0.6:\n",
    "        print(\"üü¢ Performance globale: BONNE\")\n",
    "    else:\n",
    "        print(\"üü° Performance globale: √Ä AM√âLIORER\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucun r√©sultat √† sauvegarder. Ex√©cutez d'abord les sections pr√©c√©dentes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01c161",
   "metadata": {},
   "source": [
    "## üéØ 8. Conclusion et Guide d'Utilisation\n",
    "\n",
    "### ‚úÖ F√©licitations !\n",
    "\n",
    "Vous avez termin√© avec succ√®s l'utilisation du syst√®me de pr√©diction √©nerg√©tique LSTM !\n",
    "\n",
    "### üìã R√©capitulatif des √©tapes accomplies :\n",
    "\n",
    "1. **‚öôÔ∏è Configuration** - Choix entre mod√®les pr√©-entra√Æn√©s ou r√©-entra√Ænement\n",
    "2. **üìä Donn√©es** - Chargement et pr√©paration des donn√©es\n",
    "3. **ü§ñ Mod√®les** - Utilisation ou cr√©ation des mod√®les LSTM\n",
    "4. **üîÆ Pr√©dictions** - G√©n√©ration des pr√©dictions futures (30 jours)\n",
    "5. **üìà √âvaluation** - Calcul des m√©triques de performance\n",
    "6. **üíæ Sauvegarde** - Export des r√©sultats en CSV et rapport de synth√®se\n",
    "\n",
    "### üìÅ Fichiers g√©n√©r√©s :\n",
    "\n",
    "- **Pr√©dictions futures** : `[variable]_predictions_futures_[timestamp].csv`\n",
    "- **√âvaluations** : `[variable]_evaluation_[timestamp].csv`  \n",
    "- **M√©triques** : `metriques_modeles_[timestamp].csv`\n",
    "- **Rapport** : `rapport_synthese_[timestamp].txt`\n",
    "- **Mod√®les sauv√©s** : Dossiers `models/` et `scalers/`\n",
    "\n",
    "### üîÑ Pour de nouvelles pr√©dictions :\n",
    "\n",
    "1. **Nouvelles donn√©es** : Changez le fichier dans la section 2\n",
    "2. **Nouveaux mod√®les** : S√©lectionnez \"R√©-entra√Æner\" dans la section 2\n",
    "3. **Param√®tres** : Modifiez `SEQUENCE_LENGTH` et `PREDICTION_DAYS` dans la section 5\n",
    "\n",
    "### üìû Support :\n",
    "\n",
    "Pour toute question ou am√©lioration, consultez la documentation du projet ou contactez l'√©quipe de d√©veloppement.\n",
    "\n",
    "---\n",
    "\n",
    "**üîã Merci d'utiliser le Syst√®me de Pr√©diction √ânerg√©tique LSTM !**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13db17",
   "metadata": {},
   "source": [
    "## ü§ñ 4. Entra√Ænement des Mod√®les LSTM\n",
    "\n",
    "Cette section entra√Æne les mod√®les LSTM pour chaque variable si le mode \"retrain\" est s√©lectionn√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a837a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour l'entra√Ænement\n",
    "SEQUENCE_LENGTH = 30\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Variables √† pr√©dire\n",
    "variables_to_predict = [\n",
    "    'prectotcorr', 'suface_pressure(pa)', 'temp2_ave(c)', \n",
    "    'temp2_max(c)', 'temp2_min(c)', 'total_demand(mw)',\n",
    "    'wind_speed50_ave(ms)', 'wind_speed50_max(ms)', 'wind_speed50_min(ms)'\n",
    "]\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"Cr√©er un mod√®le LSTM optimis√©\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(100, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def prepare_sequences(data, sequence_length):\n",
    "    \"\"\"Pr√©parer les s√©quences pour l'entra√Ænement LSTM\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(data)):\n",
    "        X.append(data[i-sequence_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Dictionnaires pour stocker les mod√®les et scalers\n",
    "trained_models = {}\n",
    "trained_scalers = {}\n",
    "training_history = {}\n",
    "\n",
    "if user_mode == 'retrain':\n",
    "    print(\"üîÑ D√©but de l'entra√Ænement des mod√®les personnalis√©s...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Entra√Æner un mod√®le pour chaque variable\n",
    "    for i, variable in enumerate(variables_to_predict):\n",
    "        print(f\"\\nü§ñ Entra√Ænement du mod√®le pour : {variable}\")\n",
    "        print(f\"üìä Progression : {i+1}/{len(variables_to_predict)}\")\n",
    "        \n",
    "        if variable in df.columns:\n",
    "            # Pr√©paration des donn√©es\n",
    "            data = df[variable].values.reshape(-1, 1)\n",
    "            \n",
    "            # Normalisation\n",
    "            scaler = MinMaxScaler()\n",
    "            scaled_data = scaler.fit_transform(data)\n",
    "            \n",
    "            # Cr√©ation des s√©quences\n",
    "            X, y = prepare_sequences(scaled_data, SEQUENCE_LENGTH)\n",
    "            \n",
    "            if len(X) > 0:\n",
    "                # Division train/test\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    X, y, test_size=0.2, shuffle=False\n",
    "                )\n",
    "                \n",
    "                # Cr√©ation et entra√Ænement du mod√®le\n",
    "                model = create_lstm_model((SEQUENCE_LENGTH, 1))\n",
    "                \n",
    "                # Callbacks\n",
    "                early_stopping = EarlyStopping(\n",
    "                    monitor='val_loss', \n",
    "                    patience=10, \n",
    "                    restore_best_weights=True\n",
    "                )\n",
    "                \n",
    "                model_checkpoint = ModelCheckpoint(\n",
    "                    f'{MODELS_PATH}{variable}_LSTM.h5',\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True\n",
    "                )\n",
    "                \n",
    "                # Entra√Ænement\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    callbacks=[early_stopping, model_checkpoint],\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Sauvegarde\n",
    "                trained_models[variable] = model\n",
    "                trained_scalers[variable] = scaler\n",
    "                training_history[variable] = history.history\n",
    "                \n",
    "                # Sauvegarde du scaler\n",
    "                joblib.dump(scaler, f'{SCALERS_PATH}{variable}_scaler.pkl')\n",
    "                \n",
    "                # √âvaluation rapide\n",
    "                train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "                test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "                \n",
    "                print(f\"‚úÖ {variable} - Train Loss: {train_loss[0]:.4f}, Test Loss: {test_loss[0]:.4f}\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Donn√©es insuffisantes pour {variable}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Variable {variable} non trouv√©e dans les donn√©es\")\n",
    "    \n",
    "    print(\"\\nüéâ Entra√Ænement termin√© pour tous les mod√®les!\")\n",
    "    print(f\"üìÅ Mod√®les sauvegard√©s dans : {MODELS_PATH}\")\n",
    "    print(f\"üìÅ Scalers sauvegard√©s dans : {SCALERS_PATH}\")\n",
    "\n",
    "else:\n",
    "    print(\"üéØ Utilisation des mod√®les pr√©-entra√Æn√©s...\")\n",
    "    \n",
    "    # Charger les mod√®les pr√©-entra√Æn√©s\n",
    "    for variable in variables_to_predict:\n",
    "        model_path = f'{MODELS_PATH}{variable}_LSTM.h5'\n",
    "        scaler_path = f'{SCALERS_PATH}{variable}_scaler.pkl'\n",
    "        \n",
    "        if os.path.exists(model_path) and os.path.exists(scaler_path):\n",
    "            try:\n",
    "                trained_models[variable] = load_model(model_path)\n",
    "                trained_scalers[variable] = joblib.load(scaler_path)\n",
    "                print(f\"‚úÖ Mod√®le charg√© pour {variable}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erreur lors du chargement de {variable}: {e}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Mod√®le pr√©-entra√Æn√© non trouv√© pour {variable}\")\n",
    "\n",
    "print(f\"\\nüìä Mod√®les disponibles : {len(trained_models)}\")\n",
    "print(f\"üîß Scalers disponibles : {len(trained_scalers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des r√©sultats pour l'interface Streamlit\n",
    "def save_results_for_streamlit(predictions_results, output_path=\"../results.csv\"):\n",
    "    \"\"\"Sauvegarde les r√©sultats dans le format attendu par Streamlit\"\"\"\n",
    "    \n",
    "    # Cr√©er un DataFrame avec les r√©sultats\n",
    "    results_data = []\n",
    "    \n",
    "    # G√©n√©rer les dates futures (30 jours √† partir d'aujourd'hui)\n",
    "    from datetime import datetime, timedelta\n",
    "    base_date = datetime.now()\n",
    "    \n",
    "    # Prendre le premier mod√®le pour d√©terminer le nombre de pr√©dictions\n",
    "    first_key = list(predictions_results.keys())[0]\n",
    "    num_predictions = len(predictions_results[first_key]['future_predictions'])\n",
    "    \n",
    "    for i in range(num_predictions):\n",
    "        date = (base_date + timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Initialiser le dictionnaire de r√©sultats pour ce jour\n",
    "        result_row = {'date': date}\n",
    "        \n",
    "        # Ajouter les pr√©dictions pour chaque variable\n",
    "        for variable, data in predictions_results.items():\n",
    "            if i < len(data['future_predictions']):\n",
    "                result_row[f'{variable}_predit'] = data['future_predictions'][i]\n",
    "        \n",
    "        # Calculer g√©n√©ration et consommation si les variables appropri√©es existent\n",
    "        generation_vars = ['prectotcorr', 'wind_speed50_ave(ms)', 'wind_speed50_max(ms)']\n",
    "        consumption_vars = ['total_demand(mw)', 'temp2_ave(c)', 'temp2_max(c)']\n",
    "        \n",
    "        # Estimation de la g√©n√©ration (bas√©e sur les variables m√©t√©o)\n",
    "        generation = 0\n",
    "        gen_count = 0\n",
    "        for var in generation_vars:\n",
    "            if f'{var}_predit' in result_row:\n",
    "                # Normalisation et pond√©ration pour estimation g√©n√©ration\n",
    "                if 'wind' in var:\n",
    "                    generation += result_row[f'{var}_predit'] * 10  # Facteur √©olien\n",
    "                    gen_count += 1\n",
    "                elif 'prectot' in var:\n",
    "                    generation += result_row[f'{var}_predit'] * 5   # Facteur hydro√©lectrique\n",
    "                    gen_count += 1\n",
    "        \n",
    "        if gen_count > 0:\n",
    "            generation = generation / gen_count\n",
    "        else:\n",
    "            generation = 100  # Valeur par d√©faut\n",
    "        \n",
    "        # Consommation (bas√©e sur la demande totale ou temp√©rature)\n",
    "        consumption = 0\n",
    "        cons_count = 0\n",
    "        for var in consumption_vars:\n",
    "            if f'{var}_predit' in result_row:\n",
    "                if 'demand' in var:\n",
    "                    consumption = result_row[f'{var}_predit']  # Demande directe\n",
    "                    cons_count = 1\n",
    "                    break\n",
    "                elif 'temp' in var:\n",
    "                    # Estimation bas√©e sur la temp√©rature\n",
    "                    temp = result_row[f'{var}_predit']\n",
    "                    consumption += abs(temp - 20) * 5  # Facteur de climatisation/chauffage\n",
    "                    cons_count += 1\n",
    "        \n",
    "        if cons_count == 0:\n",
    "            consumption = 80  # Valeur par d√©faut\n",
    "        elif 'demand' not in [var for var in consumption_vars if f'{var}_predit' in result_row]:\n",
    "            consumption = consumption / cons_count\n",
    "        \n",
    "        result_row['generation_predite'] = max(0, generation)\n",
    "        result_row['consommation_predite'] = max(0, consumption)\n",
    "        \n",
    "        results_data.append(result_row)\n",
    "    \n",
    "    # Cr√©er le DataFrame final\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Sauvegarder en CSV\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ R√©sultats sauvegard√©s pour Streamlit : {output_path}\")\n",
    "    print(f\"üìä {len(results_df)} jours de pr√©dictions sauvegard√©es\")\n",
    "    \n",
    "    # Afficher un aper√ßu\n",
    "    print(\"\\\\nüìã Aper√ßu des r√©sultats :\")\n",
    "    display(results_df.head())\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Ex√©cuter la sauvegarde si des pr√©dictions ont √©t√© g√©n√©r√©es\n",
    "if 'all_predictions' in globals() and all_predictions:\n",
    "    print(\"üíæ Sauvegarde des r√©sultats pour l'interface Streamlit...\")\n",
    "    streamlit_results = save_results_for_streamlit(all_predictions)\n",
    "    print(\"‚úÖ Sauvegarde termin√©e !\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Aucune pr√©diction trouv√©e √† sauvegarder\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
